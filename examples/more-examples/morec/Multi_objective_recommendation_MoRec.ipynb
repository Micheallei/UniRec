{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation.</i>\n",
    "\n",
    "<i>Licensed under the MIT license.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoRec: A Data-Centric Multi-Objective Learning Framework for Responsible Recommendation Systems\n",
    "\n",
    "MoRec[[1]](https://arxiv.org/abs/2310.13260v1) is a data-centric multi-objective framework designed for responsible recommendation systems. Concretely, MoRec adopts a tri-level framework to optimize diverse objectives simultaneously, comprising a PID-based objective coordinator for trade-off among objectives and an adaptive data sampler for unified objective modeling. \n",
    "\n",
    "\n",
    "## Strengths of MoRec\n",
    "- MoRec is model-agnostic, which is capable of converting an accuracy-oriented model to multi-objective model\n",
    "- MoRec adopts a post-training strategy, which is able to convert a well-trained model to multi-objective model at a low cost\n",
    "- MoRec exhibit great capability in objective controlling, which could optimize model with objective preference without sacrificing too much accuracy\n",
    "\n",
    "## Data requirements\n",
    "\n",
    "MoRec is capable of optimizing accuracy, revenue, fairness and alignment objectives simultaneously. \n",
    "\n",
    "- For accuracy, basical user-item interaction files are required, including `train.csv`, `valid.csv`, `test.csv` and `user_history.csv`. \n",
    "  `train.csv`, `valid.csv`, `test.csv` represent interactions in training set, validation set and test set respectively, which are formatted as follows:\n",
    "\n",
    "  | user_id | item_id |\n",
    "  |---------|---------|\n",
    "  | 1       | 1       |\n",
    "  | 1       | 2       |\n",
    "  | ...     | ...     |\n",
    "  | 100     | 254     |\n",
    "  | ...     | ...     |\n",
    "\n",
    "  `user_history.csv` represents the user's interaction history, consist of interactions in training set and validation set, which is formatted as follows:\n",
    "\n",
    "  | user_id | item_seq |\n",
    "  |---------|---------|\n",
    "  | 1       | 1,2,3,...|\n",
    "  | ...     | ...     |\n",
    "  | 100     | 254,257,327,... |\n",
    "  | ...     | ...     |\n",
    "\n",
    "- For revenue, MoRec would sample data samples according to their weights, i.e. item price. For fairness, MoRec aims to improve the accuracy preformance of the most disadvantaged group. For alignment, MoRec targets on aligning the model's distribution with some pre-defined expectation distribution. To model those objectives, `item_meta_morec_filename` is required to provide item weights, fairness group and alignment group. And if you want to set the pre-set distribution for alignment,  `align_dist_filename` is needed. By default, the expected distribution to aligned with is the distribution derived from the training set. Here are the example of item_meta_morec_file  and align_dist_file.\n",
    "  \n",
    "  - item_meta_morec_file: `item_meta_morec.csv`, columns separated by comma\n",
    "\n",
    "    | item_id | weight | fair_group | align_group |\n",
    "    |---------|---------|---------|---------|\n",
    "    | 1       | 2.35    |  1  |  2 |\n",
    "    | 2       | 63.21   |  5  |  1 |\n",
    "    | ...     | ...     | ... | ... |\n",
    "    | 100     | 5.89   |  5  |  4 |\n",
    "    | ...     | ...     | ... | ... |\n",
    "\n",
    "  - align_dist_file: `expected_align_dist.csv`, columns separated by comma\n",
    "\n",
    "    | group_id | proportion |\n",
    "    |---------|---------|\n",
    "    | 1       | 0.21 |\n",
    "    | 2     | 0.12    |\n",
    "    | 3    | 0.33 |\n",
    "    | 4    | 0.22    |\n",
    "    | 5    | 0.12   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: MovieLens-100k dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation\n",
    "\n",
    "We put the script for downloading and preprocessing ml-100k into the our [example folder](../../preprocess/download_split_ml100k.py). Here we would call the functions defined in the script. The preprocessed csv files would be saved in `~/.unirec/dataset/ml-100k`. \n",
    "\n",
    "We believe that you could easily process your own dataset to obtain `train.csv`, `valid.csv`, `test.csv` and `user_history.csv` using leave-one-out strategy. \n",
    "\n",
    "As for the columns in `item_meta_morec.csv` file, we fake it with random numbers due to lack of information in ml-100k. But you can easily obtain it in your own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load raw dataset from /home/v-huangxu/.unirec/dataset/ml-100k.zip\n",
      "Unzip raw dataset compressed file into /home/v-huangxu/.unirec/dataset\n",
      "original dataset size: (100000, 4)\n",
      "filter by rating>=3 dataset size: (82520, 4)\n",
      "drop_duplicates dataset size: (82520, 4)\n",
      "Ite: 0, users: 941 / 943, items: 1016 / 1574\n",
      "Ite: 1, users: 939 / 941, items: 1016 / 1016\n",
      "Ite: 2, users: 939 / 939, items: 1016 / 1016\n",
      "k-core filtered dataset size: (80393, 4)\n",
      "939 1016\n",
      "size in Train/Valid/Test: (78515, 2) / (939, 2) / (939, 2)\n",
      "Processed dataset saved in /home/v-huangxu/.unirec/dataset/ml-100k.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../../\"))\n",
    "\n",
    "from preprocess.download_split_ml100k import prepare_ml100k\n",
    "\n",
    "prepare_ml100k()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary Data File Preparation\n",
    "\n",
    "Upon the interaction files are processed, UniRec requires to convert them into binary files for time-saving loading. We provide the tools in [example folder](../../preprocess/prepare_data.py) to easily obtain the pickle file.\n",
    "\n",
    "Note that the function `process_transaction_dataset` requires some meta information of the csv files, such as the directory path, the seperator, header , file format and so on. \n",
    "\n",
    "Note that we have defined several data formats in UniRec, you can list all formats using codes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFileFormat.T1: user-item\n",
      "DataFileFormat.T2: user-item-label\n",
      "DataFileFormat.T2_1: user-item-label-session\n",
      "DataFileFormat.T3: user-item-rating\n",
      "DataFileFormat.T4: user-item_group-label_group\n",
      "DataFileFormat.T5: user-item_seq\n",
      "DataFileFormat.T5_1: user_item_seq\n",
      "DataFileFormat.T6: user-item_seq-time_seq\n",
      "DataFileFormat.T7: label-index_group-value_group\n"
     ]
    }
   ],
   "source": [
    "# All supported data file formats\n",
    "\n",
    "from unirec.constants.protocols import DataFileFormat\n",
    "\n",
    "for format in DataFileFormat.__members__.values():\n",
    "    print(f\"{format}: {format.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unirec\n",
    "\n",
    "from preprocess.prepare_data import process_transaction_dataset\n",
    "\n",
    "binary_data_folder_path = os.path.expanduser(\"~/.unirec/dataset/binary/\")\n",
    "\n",
    "UNIREC_PATH = os.path.dirname(unirec.__file__)\n",
    "\n",
    "BINARY_FILE_CONFIG = {\n",
    "    \"raw_datapath\": os.path.expanduser(\"~/.unirec/dataset/ml-100k\"), # the dir of csv files\n",
    "    \"outpathroot\": binary_data_folder_path, # the output dir of processed binary files\n",
    "    \"dataset_name\": \"ml-100k\", # the dataset name, set as you like\n",
    "    \"example_yaml_file\": os.path.join(UNIREC_PATH, \"config/dataset/example.yaml\"), # Do not modify the value\n",
    "    \"index_by_zero\": 0,  # whether the user_id and item_id start from 0\n",
    "    \"sep\": \"\\t\" ,   # the seperator of csv files \n",
    "    \"train_file\": 'train.csv',  # the filename of training csv file\n",
    "    \"train_file_format\": 'user-item', \n",
    "    \"train_file_has_header\": 1, # whether the training file has header\n",
    "    \"train_file_col_names\": \"['user_id', 'item_id']\",  # the columns of training csv file\n",
    "    \"train_neg_k\": 0,  \n",
    "    \"valid_file\": 'valid.csv', # the filename of validation csv file\n",
    "    \"valid_file_format\": 'user-item', \n",
    "    \"valid_file_has_header\": 1, # whether the validation file has header\n",
    "    \"valid_file_col_names\": \"['user_id', 'item_id']\", # the columns of validation csv file\n",
    "    \"valid_neg_k\": 0, \n",
    "    \"test_file\": 'test.csv', # the filename of test csv file\n",
    "    \"test_file_format\": 'user-item', \n",
    "    \"test_file_has_header\": 1, # whether the test file has header\n",
    "    \"test_file_col_names\": \"['user_id', 'item_id']\", # the columns of test csv file\n",
    "    \"test_neg_k\": 0, \n",
    "    \"user_history_file\": 'user_history.csv', # the filename of history csv file\n",
    "    \"user_history_file_format\": 'user-item_seq', \n",
    "    \"user_history_file_has_header\": 1, # whether the history file has header\n",
    "    \"user_history_file_col_names\": \"['user_id', 'item_seq']\" # the columns of history csv file\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape of train.csv is (78515, 2)\n",
      "data dtypes is user_id    int64\n",
      "item_id    int64\n",
      "dtype: object\n",
      "saving train.pkl at 25/10/2023 20:09:34\n",
      "finish saving train.pkl at 25/10/2023 20:09:34\n",
      "In saving:\n",
      "   user_id  item_id\n",
      "0        1        1\n",
      "1        1        2\n",
      "2        1        3\n",
      "3        1        4\n",
      "4        1        5\n",
      "data.shape=(78515, 2)\n",
      "\n",
      "data shape of valid.csv is (939, 2)\n",
      "data dtypes is user_id    int64\n",
      "item_id    int64\n",
      "dtype: object\n",
      "saving valid.pkl at 25/10/2023 20:09:34\n",
      "finish saving valid.pkl at 25/10/2023 20:09:34\n",
      "In saving:\n",
      "   user_id  item_id\n",
      "0        1      211\n",
      "1        2      252\n",
      "2        3      278\n",
      "3        4      285\n",
      "4        5      140\n",
      "data.shape=(939, 2)\n",
      "\n",
      "data shape of test.csv is (939, 2)\n",
      "data dtypes is user_id    int64\n",
      "item_id    int64\n",
      "dtype: object\n",
      "saving test.pkl at 25/10/2023 20:09:34\n",
      "finish saving test.pkl at 25/10/2023 20:09:34\n",
      "In saving:\n",
      "   user_id  item_id\n",
      "0        1      212\n",
      "1        2      253\n",
      "2        3       12\n",
      "3        4      286\n",
      "4        5       31\n",
      "data.shape=(939, 2)\n",
      "\n",
      "data shape of user_history.csv is (939, 2)\n",
      "data dtypes is user_id      int64\n",
      "item_seq    object\n",
      "dtype: object\n",
      "saving user_history.pkl at 25/10/2023 20:09:34\n",
      "finish saving user_history.pkl at 25/10/2023 20:09:34\n",
      "In saving:\n",
      "   user_id                                           item_seq\n",
      "0        1  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n",
      "1        2  [213, 198, 214, 215, 216, 217, 218, 219, 220, ...\n",
      "2        3  [254, 106, 220, 255, 256, 257, 258, 259, 260, ...\n",
      "3        4  [198, 216, 248, 268, 262, 220, 273, 270, 279, ...\n",
      "4        5  [197, 287, 34, 288, 289, 17, 9, 32, 290, 190, ...\n",
      "data.shape=(939, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_transaction_dataset(BINARY_FILE_CONFIG)    # the binary files would be saved in `binary_data_folder_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/v-huangxu/.unirec/dataset/binary/ml-100k/item_meta_morec.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the item_meta_morec.csv file, we copy it to the binary file path as well\n",
    "import shutil\n",
    "\n",
    "shutil.copyfile(os.path.join(BINARY_FILE_CONFIG['raw_datapath'], 'item_meta_morec.csv'), os.path.join(BINARY_FILE_CONFIG['outpathroot'], BINARY_FILE_CONFIG['dataset_name'], 'item_meta_morec.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MoRec pretraining stage: accuracy-oriented model training\n",
    "\n",
    "Since MoRec provides a post-training strategy to convert a single-objective model (usually an accuracy-oriented model) to a multi-objective model, we need to train the accuracy-oriented model first.\n",
    "\n",
    "1. First, setup morec_configurations, including hyperparameters, file paths.\n",
    "2. Second, training with unirec's user-friendly interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from copy import deepcopy\n",
    "\n",
    "ckpt_output_path = os.path.expanduser(\"~/.unirec/output\")\n",
    "\n",
    "GLOBAL_CONF = {\n",
    "    'config_dir': f\"{os.path.join(UNIREC_PATH, 'config')}\",\n",
    "    'exp_name': '',\n",
    "    'checkpoint_dir': datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"),\n",
    "    'model': 'MF',\n",
    "    'dataloader': 'BaseDataset',\n",
    "    'dataset': 'ml-100k',\n",
    "    'dataset_path': os.path.join(BINARY_FILE_CONFIG['outpathroot'], \"ml-100k\"),\n",
    "    'output_path': ckpt_output_path,\n",
    "    'learning_rate': 0.001,\n",
    "    'scheduler': None,\n",
    "    'dropout_prob': 0.0,\n",
    "    'embedding_size': 32,\n",
    "    'user_pre_item_emb': 0,\n",
    "    'loss_type': 'bpr',\n",
    "    'max_seq_len': 10,\n",
    "    'has_user_bias': 0,\n",
    "    'has_item_bias': 0,\n",
    "    'epochs':100,\n",
    "    'early_stop': 10,\n",
    "    'batch_size': 512,\n",
    "    'n_sample_neg_train': 4,\n",
    "    'valid_protocol': 'one_vs_all',\n",
    "    'test_protocol': 'one_vs_all',\n",
    "    'grad_clip_value': 0.1,\n",
    "    'weight_decay': 1e-6,\n",
    "    'history_mask_mode': 'autoagressive',\n",
    "    'user_history_filename': \"user_history\",\n",
    "    'metrics': \"['hit@10', 'rhit@10', 'pop-kl@10', 'least-misery']\",\n",
    "    'key_metric': \"hit@10\",\n",
    "    'num_workers': 4,\n",
    "    'num_workers_test': 0,\n",
    "    'verbose': 2,\n",
    "    'neg_by_pop_alpha': 0,\n",
    "    'item_meta_morec_filename': 'item_meta_morec.csv',\n",
    "    'align_dist_filename': None,  # the expected alignment distribution is set as the distribution derived from the training set\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load configuration files from /anaconda/envs/unirec/lib/python3.9/site-packages/unirec/config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] MF-MoRec-Pretrain: config={'gpu_id': 0, 'use_gpu': True, 'seed': 2022, 'state': 'INFO', 'verbose': 2, 'saved': True, 'use_tensorboard': False, 'use_wandb': False, 'init_method': 'normal', 'init_std': 0.02, 'init_mean': 0.0, 'scheduler': None, 'scheduler_factor': 0.1, 'time_seq': 0, 'seq_last': False, 'has_user_emb': True, 'has_user_bias': 0, 'has_item_bias': 0, 'use_features': False, 'use_text_emb': False, 'use_position_emb': True, 'load_pretrained_model': False, 'embedding_size': 32, 'hidden_size': 128, 'inner_size': 128, 'dropout_prob': 0.0, 'epochs': 100, 'batch_size': 512, 'learning_rate': 0.001, 'optimizer': 'adam', 'eval_step': 1, 'early_stop': 10, 'clip_grad_norm': None, 'weight_decay': 1e-06, 'num_workers': 4, 'persistent_workers': False, 'pin_memory': False, 'shuffle_train': False, 'use_pre_item_emb': 0, 'loss_type': 'bpr', 'ccl_w': 150, 'ccl_m': 0.4, 'distance_type': 'dot', 'metrics': \"['hit@10', 'rhit@10', 'pop-kl@10', 'least-misery']\", 'key_metric': 'hit@10', 'test_protocol': 'one_vs_all', 'valid_protocol': 'one_vs_all', 'test_batch_size': 100, 'model': 'MF', 'dataloader': 'BaseDataset', 'max_seq_len': 10, 'history_mask_mode': 'autoagressive', 'tau': 1.0, 'enable_morec': 0, 'morec_objectives': ['fairness', 'alignment', 'revenue'], 'morec_objective_controller': 'PID', 'morec_ngroup': [10, 10, -1], 'morec_alpha': 0.1, 'morec_lambda': 0.2, 'morec_expect_loss': 0.2, 'morec_beta_min': 0.6, 'morec_beta_max': 1.3, 'morec_K_p': 0.01, 'morec_K_i': 0.001, 'morec_objective_weights': '[0.3,0.3,0.4]', 'group_size': -1, 'n_items': 1017, 'n_neg_test_from_sampling': 0, 'n_neg_train_from_sampling': 0, 'n_neg_valid_from_sampling': 0, 'n_users': 940, 'test_file_format': 'user-item', 'train_file_format': 'user-item', 'user_history_file_format': 'user-item_seq', 'valid_file_format': 'user-item', 'config_dir': '/anaconda/envs/unirec/lib/python3.9/site-packages/unirec/config', 'exp_name': 'MF-MoRec-Pretrain', 'checkpoint_dir': 'morec_pretrain_2023-10-25_20-09-34', 'dataset': 'ml-100k', 'dataset_path': '/home/v-huangxu/.unirec/dataset/binary/ml-100k', 'output_path': '/home/v-huangxu/.unirec/output', 'user_pre_item_emb': 0, 'n_sample_neg_train': 4, 'grad_clip_value': 0.1, 'user_history_filename': 'user_history', 'num_workers_test': 0, 'neg_by_pop_alpha': 0, 'item_meta_morec_filename': 'item_meta_morec.csv', 'align_dist_filename': None, 'cmd_args': {'config_dir': '/anaconda/envs/unirec/lib/python3.9/site-packages/unirec/config', 'exp_name': 'MF-MoRec-Pretrain', 'checkpoint_dir': 'morec_pretrain_2023-10-25_20-09-34', 'model': 'MF', 'dataloader': 'BaseDataset', 'dataset': 'ml-100k', 'dataset_path': '/home/v-huangxu/.unirec/dataset/binary/ml-100k', 'output_path': '/home/v-huangxu/.unirec/output', 'learning_rate': 0.001, 'scheduler': None, 'dropout_prob': 0.0, 'embedding_size': 32, 'user_pre_item_emb': 0, 'loss_type': 'bpr', 'max_seq_len': 10, 'has_user_bias': 0, 'has_item_bias': 0, 'epochs': 100, 'early_stop': 10, 'batch_size': 512, 'n_sample_neg_train': 4, 'valid_protocol': 'one_vs_all', 'test_protocol': 'one_vs_all', 'grad_clip_value': 0.1, 'weight_decay': 1e-06, 'history_mask_mode': 'autoagressive', 'user_history_filename': 'user_history', 'metrics': \"['hit@10', 'rhit@10', 'pop-kl@10', 'least-misery']\", 'key_metric': 'hit@10', 'num_workers': 4, 'num_workers_test': 0, 'verbose': 2, 'neg_by_pop_alpha': 0, 'item_meta_morec_filename': 'item_meta_morec.csv', 'align_dist_filename': None, 'logger_time_str': '2023-10-25_200935', 'logger_rand': 85}, 'device': device(type='cuda'), 'task': 'train', 'logger_time_str': '2023-10-25_200935', 'logger_rand': 85}\n",
      "[INFO] MF-MoRec-Pretrain: Loading user history from user_history ...\n",
      "[INFO] MF-MoRec-Pretrain: Done. 940 of users have history.\n",
      "[INFO] MF-MoRec-Pretrain: Constructing dataset of task type: train\n",
      "[DEBUG] MF-MoRec-Pretrain: loading train at 25/10/2023 20:09:36\n",
      "[DEBUG] MF-MoRec-Pretrain: Finished loading train at 25/10/2023 20:09:36\n",
      "[INFO] MF-MoRec-Pretrain: Finished initializing <class 'unirec.data.dataset.basedataset.BaseDataset'>\n",
      "[INFO] MF-MoRec-Pretrain: Constructing dataset of task type: valid\n",
      "[DEBUG] MF-MoRec-Pretrain: loading valid at 25/10/2023 20:09:36\n",
      "[DEBUG] MF-MoRec-Pretrain: Finished loading valid at 25/10/2023 20:09:36\n",
      "[INFO] MF-MoRec-Pretrain: Finished initializing <class 'unirec.data.dataset.basedataset.BaseDataset'>\n",
      "[INFO] MF-MoRec-Pretrain: MF(\n",
      "  (scorer_layers): InnerProductScorer()\n",
      "  (user_embedding): Embedding(940, 32, padding_idx=0)\n",
      "  (item_embedding): Embedding(1017, 32, padding_idx=0)\n",
      ")\n",
      "Trainable parameter number: 62624\n",
      "All trainable parameters:\n",
      "user_embedding.weight : torch.Size([940, 32])\n",
      "item_embedding.weight : torch.Size([1017, 32])\n",
      "[DEBUG] MF-MoRec-Pretrain: >> Valid before training...\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing logs to /home/v-huangxu/.unirec/output/MF-MoRec-Pretrain.2023-10-25_200935.85.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 0 evaluating [time: 2.47s, hit@10: 0.006390]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.006389776357827476 min-hit@10:0.0 min-rhit@10:0.0 pop-kl@10:0.006275205722284025 rhit@10:0.3903478411526107\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 0 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 1\n",
      "Train: 100%|██████████| 154/154 [00:01<00:00, 116.79it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 1 training [time: 1.32s, train loss: 106.7443]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  8.40it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 1 evaluating [time: 0.24s, hit@10: 0.018104]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.01810436634717785 min-hit@10:0.009950248756218905 min-rhit@10:0.7130259394968312 pop-kl@10:0.0069606678917607315 rhit@10:1.1928485233078796\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 1 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 2\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 182.28it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 2 training [time: 0.85s, train loss: 106.1837]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.60it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 2 evaluating [time: 0.31s, hit@10: 0.079872]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.07987220447284345 min-hit@10:0.06578947368421052 min-rhit@10:4.820387036416506 pop-kl@10:0.011831469372388692 rhit@10:5.126112425606642\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 2 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 3\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 183.53it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 3 training [time: 0.84s, train loss: 101.5265]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  7.40it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 3 evaluating [time: 0.28s, hit@10: 0.092652]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.0926517571884984 min-hit@10:0.08552631578947369 min-rhit@10:6.065609806709919 pop-kl@10:0.01955960294135002 rhit@10:6.276264684569161\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 3 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 4\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 181.38it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 4 training [time: 0.85s, train loss: 91.7965]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.90it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 4 evaluating [time: 0.29s, hit@10: 0.097977]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.0979765708200213 min-hit@10:0.0845771144278607 min-rhit@10:5.90681793746452 pop-kl@10:0.027855237533565474 rhit@10:6.563049826603306\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 4 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 5\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 182.80it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 5 training [time: 0.84s, train loss: 81.2614]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.62it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 5 evaluating [time: 0.31s, hit@10: 0.100106]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.10010649627263046 min-hit@10:0.08955223880597014 min-rhit@10:6.04691364144022 pop-kl@10:0.03324622241834523 rhit@10:6.710711221137682\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 5 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 6\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.66it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 6 training [time: 0.86s, train loss: 72.2311]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.68it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 6 evaluating [time: 0.30s, hit@10: 0.108626]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.10862619808306709 min-hit@10:0.09239130434782608 min-rhit@10:6.502437721908586 pop-kl@10:0.03892119111962909 rhit@10:7.0603528316367035\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 6 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 7\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.05it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 7 training [time: 0.87s, train loss: 65.7940]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.55it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 7 evaluating [time: 0.36s, hit@10: 0.115016]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.11501597444089456 min-hit@10:0.0945273631840796 min-rhit@10:6.337122482770289 pop-kl@10:0.04047395003723528 rhit@10:7.4712824879167234\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 7 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 8\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 177.10it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 8 training [time: 0.87s, train loss: 61.5920]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.41it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 8 evaluating [time: 0.32s, hit@10: 0.113951]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.11395101171458999 min-hit@10:0.08695652173913043 min-rhit@10:6.526789911753254 pop-kl@10:0.033586904833486204 rhit@10:7.330784308870076\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 9\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.03it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 9 training [time: 0.86s, train loss: 58.4080]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.99it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 9 evaluating [time: 0.29s, hit@10: 0.112886]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.11288604898828541 min-hit@10:0.09239130434782608 min-rhit@10:6.170321988152773 pop-kl@10:0.03313113242421157 rhit@10:7.192043088489477\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 10\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 182.89it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 10 training [time: 0.84s, train loss: 56.1507]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.58it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 10 evaluating [time: 0.31s, hit@10: 0.108626]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.10862619808306709 min-hit@10:0.08955223880597014 min-rhit@10:5.614190619025877 pop-kl@10:0.035657101861221396 rhit@10:6.873720480882877\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 11\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 181.35it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 11 training [time: 0.85s, train loss: 53.8454]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.88it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 11 evaluating [time: 0.30s, hit@10: 0.109691]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.10969116080937168 min-hit@10:0.09782608695652174 min-rhit@10:6.969125181013732 pop-kl@10:0.03497113578562711 rhit@10:6.983773468356836\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 4 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 12\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 181.10it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 12 training [time: 0.85s, train loss: 52.3615]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.23it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 12 evaluating [time: 0.33s, hit@10: 0.116081]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.11608093716719915 min-hit@10:0.10869565217391304 min-rhit@10:7.430618783516579 pop-kl@10:0.03105995376400051 rhit@10:7.208651687448415\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 12 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 13\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 181.66it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 13 training [time: 0.85s, train loss: 50.5475]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.18it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 13 evaluating [time: 0.33s, hit@10: 0.113951]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.11395101171458999 min-hit@10:0.10326086956521739 min-rhit@10:7.179264174389599 pop-kl@10:0.030201127237378965 rhit@10:7.057062737168954\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 14\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 181.75it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 14 training [time: 0.85s, train loss: 49.2308]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.07it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 14 evaluating [time: 0.33s, hit@10: 0.115016]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.11501597444089456 min-hit@10:0.09782608695652174 min-rhit@10:6.728306100705386 pop-kl@10:0.028250657737941942 rhit@10:7.047305303824309\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 15\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 180.77it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 15 training [time: 0.85s, train loss: 47.8915]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.68it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 15 evaluating [time: 0.30s, hit@10: 0.116081]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.11608093716719915 min-hit@10:0.10326086956521739 min-rhit@10:7.163904057020632 pop-kl@10:0.026296763290996207 rhit@10:7.277767784186472\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 16\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.44it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 16 training [time: 0.86s, train loss: 46.9562]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.43it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 16 evaluating [time: 0.32s, hit@10: 0.116081]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.11608093716719915 min-hit@10:0.10869565217391304 min-rhit@10:7.167170585403319 pop-kl@10:0.024684034392125964 rhit@10:7.212350825645965\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 4 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 17\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.47it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 17 training [time: 0.86s, train loss: 45.9545]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.87it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 17 evaluating [time: 0.34s, hit@10: 0.117146]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.11714589989350373 min-hit@10:0.10526315789473684 min-rhit@10:7.163904057020632 pop-kl@10:0.022363024347721593 rhit@10:7.218189206479562\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 17 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 18\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 174.25it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 18 training [time: 0.89s, train loss: 44.8897]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.66it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 18 evaluating [time: 0.30s, hit@10: 0.115016]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.11501597444089456 min-hit@10:0.10526315789473684 min-rhit@10:6.7998354088236415 pop-kl@10:0.021617315397397596 rhit@10:7.1518344204857085\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 19\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 180.86it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 19 training [time: 0.85s, train loss: 44.1027]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.83it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 19 evaluating [time: 0.30s, hit@10: 0.119276]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.11927582534611289 min-hit@10:0.09868421052631579 min-rhit@10:7.107394054239798 pop-kl@10:0.019139739351722432 rhit@10:7.279333843901623\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 19 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 20\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 182.62it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 20 training [time: 0.85s, train loss: 43.2838]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.31it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 20 evaluating [time: 0.32s, hit@10: 0.117146]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.11714589989350373 min-hit@10:0.09868421052631579 min-rhit@10:6.963391133650877 pop-kl@10:0.018216366282141166 rhit@10:7.231337314185068\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 21\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 183.54it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 21 training [time: 0.84s, train loss: 42.5263]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.19it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 21 evaluating [time: 0.33s, hit@10: 0.116081]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.11608093716719915 min-hit@10:0.09210526315789473 min-rhit@10:6.225996596080969 pop-kl@10:0.018207791525598344 rhit@10:7.009148818016926\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 22\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.02it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 22 training [time: 0.87s, train loss: 41.7174]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.54it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 22 evaluating [time: 0.31s, hit@10: 0.119276]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.11927582534611289 min-hit@10:0.09210526315789473 min-rhit@10:6.456350489906507 pop-kl@10:0.016871778731804028 rhit@10:7.178996136602242\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 23\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 180.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 23 training [time: 0.86s, train loss: 40.7306]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.82it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 23 evaluating [time: 0.30s, hit@10: 0.126731]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.12673056443024494 min-hit@10:0.10526315789473684 min-rhit@10:6.622010083989507 pop-kl@10:0.016228533105220565 rhit@10:7.51469249043957\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 23 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 24\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.86it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 24 training [time: 0.86s, train loss: 40.2935]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.70it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 24 evaluating [time: 0.36s, hit@10: 0.130990]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.13099041533546327 min-hit@10:0.10526315789473684 min-rhit@10:6.685901303108046 pop-kl@10:0.01624322668318689 rhit@10:7.734199475558625\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 24 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 25\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.46it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 25 training [time: 0.87s, train loss: 39.3514]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.16it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 25 evaluating [time: 0.33s, hit@10: 0.132055]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.13205537806176784 min-hit@10:0.10526315789473684 min-rhit@10:7.267326430446233 pop-kl@10:0.014727867756397804 rhit@10:7.927201923190935\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 25 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 26\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 177.32it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 26 training [time: 0.87s, train loss: 38.6915]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.42it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 26 evaluating [time: 0.32s, hit@10: 0.128860]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.1288604898828541 min-hit@10:0.09868421052631579 min-rhit@10:7.138981334410506 pop-kl@10:0.015032087139813802 rhit@10:7.898092918776551\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 27\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.43it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 27 training [time: 0.87s, train loss: 37.9693]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.98it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 27 evaluating [time: 0.30s, hit@10: 0.133120]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.13312034078807242 min-hit@10:0.10526315789473684 min-rhit@10:7.180233246394346 pop-kl@10:0.01407045851715261 rhit@10:8.19979330674582\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 27 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 28\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 182.98it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 28 training [time: 0.84s, train loss: 37.4139]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.38it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 28 evaluating [time: 0.32s, hit@10: 0.135250]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.13525026624068157 min-hit@10:0.1118421052631579 min-rhit@10:7.686351818633818 pop-kl@10:0.012558146581810635 rhit@10:8.339924115061477\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 28 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 29\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 181.35it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 29 training [time: 0.85s, train loss: 36.9028]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.22it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 29 evaluating [time: 0.33s, hit@10: 0.134185]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.134185303514377 min-hit@10:0.10526315789473684 min-rhit@10:7.912900447120421 pop-kl@10:0.011968058133281985 rhit@10:8.24028605283404\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 30\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.43it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 30 training [time: 0.86s, train loss: 36.3037]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.72it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 30 evaluating [time: 0.35s, hit@10: 0.137380]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.13738019169329074 min-hit@10:0.11842105263157894 min-rhit@10:8.595062621733382 pop-kl@10:0.011839629269691421 rhit@10:8.47415955091008\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 30 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 31\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.38it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 31 training [time: 0.87s, train loss: 35.8144]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.04it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 31 evaluating [time: 0.34s, hit@10: 0.137380]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.13738019169329074 min-hit@10:0.1118421052631579 min-rhit@10:7.960274130125059 pop-kl@10:0.010247943726295863 rhit@10:8.497902195060389\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 32\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.18it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 32 training [time: 0.87s, train loss: 35.0241]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.30it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 32 evaluating [time: 0.32s, hit@10: 0.140575]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.14057507987220447 min-hit@10:0.1118421052631579 min-rhit@10:8.377725504933107 pop-kl@10:0.011013238793275969 rhit@10:8.770104106607809\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 32 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 33\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 181.60it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 33 training [time: 0.85s, train loss: 34.5297]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.63it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 33 evaluating [time: 0.31s, hit@10: 0.142705]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.14270500532481364 min-hit@10:0.13157894736842105 min-rhit@10:8.503276006795879 pop-kl@10:0.010262260535673456 rhit@10:8.932546704639329\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 33 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 34\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 176.69it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 34 training [time: 0.87s, train loss: 34.1345]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.50it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 34 evaluating [time: 0.32s, hit@10: 0.143770]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.14376996805111822 min-hit@10:0.125 min-rhit@10:8.159684974325009 pop-kl@10:0.008358794312075176 rhit@10:9.01666760180639\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 34 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 35\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 182.35it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 35 training [time: 0.85s, train loss: 33.6472]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.13it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 35 evaluating [time: 0.33s, hit@10: 0.146965]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.14696485623003194 min-hit@10:0.125 min-rhit@10:8.197512001387496 pop-kl@10:0.008009639420708137 rhit@10:9.136570852017892\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 35 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 36\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 182.82it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 36 training [time: 0.84s, train loss: 33.1526]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.90it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 36 evaluating [time: 0.34s, hit@10: 0.144835]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.1448349307774228 min-hit@10:0.125 min-rhit@10:8.90832243789757 pop-kl@10:0.008079291148576487 rhit@10:9.106519107427218\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 37\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 180.64it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 37 training [time: 0.85s, train loss: 32.7545]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.26it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 37 evaluating [time: 0.32s, hit@10: 0.149095]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.14909478168264112 min-hit@10:0.13157894736842105 min-rhit@10:8.936848344350182 pop-kl@10:0.0069667744667872775 rhit@10:9.315984946491465\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 37 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 38\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 175.98it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 38 training [time: 0.88s, train loss: 32.2631]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.87it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 38 evaluating [time: 0.35s, hit@10: 0.150160]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.1501597444089457 min-hit@10:0.13815789473684212 min-rhit@10:8.938515738551008 pop-kl@10:0.006421277218086163 rhit@10:9.471884336425788\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 38 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 39\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.05it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 39 training [time: 0.86s, train loss: 31.6792]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.18it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 39 evaluating [time: 0.39s, hit@10: 0.149095]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.14909478168264112 min-hit@10:0.13157894736842105 min-rhit@10:9.36063773736507 pop-kl@10:0.006528798689529229 rhit@10:9.455732387985007\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 40\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 180.43it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 40 training [time: 0.86s, train loss: 31.3455]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.18it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 40 evaluating [time: 0.33s, hit@10: 0.151225]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.15122470713525027 min-hit@10:0.13852813852813853 min-rhit@10:8.46867732627851 pop-kl@10:0.006306128030304042 rhit@10:9.46990252982511\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 40 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 41\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 181.54it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 41 training [time: 0.85s, train loss: 30.8741]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.97it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 41 evaluating [time: 0.29s, hit@10: 0.154420]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.154419595314164 min-hit@10:0.13815789473684212 min-rhit@10:8.98410625446677 pop-kl@10:0.005769333915090118 rhit@10:9.725877984611753\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 41 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 42\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 176.89it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 42 training [time: 0.88s, train loss: 30.4094]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.93it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 42 evaluating [time: 0.29s, hit@10: 0.156550]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.15654952076677317 min-hit@10:0.1513157894736842 min-rhit@10:9.412601070788241 pop-kl@10:0.006545515193045998 rhit@10:9.838920434137963\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 42 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 43\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 180.88it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 43 training [time: 0.85s, train loss: 29.9954]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.08it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 43 evaluating [time: 0.40s, hit@10: 0.154420]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.154419595314164 min-hit@10:0.1513157894736842 min-rhit@10:9.172292839280194 pop-kl@10:0.0059668587399833994 rhit@10:9.785270313020327\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 44\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 173.57it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 44 training [time: 0.89s, train loss: 29.7063]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.38it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 44 evaluating [time: 0.32s, hit@10: 0.158679]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.15867944621938232 min-hit@10:0.1513157894736842 min-rhit@10:9.80201510473314 pop-kl@10:0.006019235648611914 rhit@10:9.99791874922525\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 44 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 45\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 180.13it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 45 training [time: 0.86s, train loss: 29.2584]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.27it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 45 evaluating [time: 0.32s, hit@10: 0.157614]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.15761448349307774 min-hit@10:0.13815789473684212 min-rhit@10:9.985993264542966 pop-kl@10:0.005725284552136374 rhit@10:9.872962222233372\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 46\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 184.54it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 46 training [time: 0.84s, train loss: 28.8383]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.19it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 46 evaluating [time: 0.33s, hit@10: 0.156550]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.15654952076677317 min-hit@10:0.14473684210526316 min-rhit@10:9.838046216358531 pop-kl@10:0.005724316093864162 rhit@10:9.990039077942281\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 47\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 181.15it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 47 training [time: 0.85s, train loss: 28.4238]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.43it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 47 evaluating [time: 0.32s, hit@10: 0.160809]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16080937167199147 min-hit@10:0.14473684210526316 min-rhit@10:10.121760677595216 pop-kl@10:0.005299261031149208 rhit@10:10.084031893781576\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 47 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 48\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 175.63it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 48 training [time: 0.88s, train loss: 28.2702]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.58it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 48 evaluating [time: 0.31s, hit@10: 0.165069]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.1650692225772098 min-hit@10:0.14473684210526316 min-rhit@10:10.04499236121062 pop-kl@10:0.004951733663617123 rhit@10:10.216239513171004\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 48 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 49\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 49 training [time: 0.87s, train loss: 27.7074]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  7.15it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 49 evaluating [time: 0.28s, hit@10: 0.160809]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16080937167199147 min-hit@10:0.13815789473684212 min-rhit@10:9.807382624275276 pop-kl@10:0.004247436050582053 rhit@10:9.938337110094626\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 50\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 175.37it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 50 training [time: 0.88s, train loss: 27.3343]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.10it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 50 evaluating [time: 0.40s, hit@10: 0.164004]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16400425985090522 min-hit@10:0.14473684210526316 min-rhit@10:10.186856664490263 pop-kl@10:0.003954630118733743 rhit@10:10.129711190734724\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 51\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 176.13it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 51 training [time: 0.88s, train loss: 27.0400]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.45it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 51 evaluating [time: 0.31s, hit@10: 0.162939]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16293929712460065 min-hit@10:0.14473684210526316 min-rhit@10:9.682544586680581 pop-kl@10:0.003987088677045941 rhit@10:10.182578543034255\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 52\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 175.24it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 52 training [time: 0.88s, train loss: 26.6210]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.86it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 52 evaluating [time: 0.35s, hit@10: 0.166134]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16613418530351437 min-hit@10:0.125 min-rhit@10:8.932425587582452 pop-kl@10:0.004003694758887087 rhit@10:10.425270341386865\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 52 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 53\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 174.19it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 53 training [time: 0.89s, train loss: 26.1735]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.50it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 53 evaluating [time: 0.31s, hit@10: 0.169329]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16932907348242812 min-hit@10:0.13157894736842105 min-rhit@10:9.576365927814306 pop-kl@10:0.0042285583982931245 rhit@10:10.622068632527158\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 53 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 54\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 181.63it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 54 training [time: 0.85s, train loss: 26.0267]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.72it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 54 evaluating [time: 0.30s, hit@10: 0.168264]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16826411075612355 min-hit@10:0.13157894736842105 min-rhit@10:9.576365927814306 pop-kl@10:0.004225066667683232 rhit@10:10.521881293632362\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 55\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 181.35it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 55 training [time: 0.85s, train loss: 25.7441]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.46it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 55 evaluating [time: 0.31s, hit@10: 0.169329]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16932907348242812 min-hit@10:0.13815789473684212 min-rhit@10:9.722723914411503 pop-kl@10:0.004373556994650162 rhit@10:10.53223108066442\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 56\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 182.39it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 56 training [time: 0.85s, train loss: 25.5051]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.61it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 56 evaluating [time: 0.31s, hit@10: 0.169329]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16932907348242812 min-hit@10:0.13815789473684212 min-rhit@10:9.46172006114193 pop-kl@10:0.004039546290570118 rhit@10:10.529708193556452\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 57\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 184.22it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 57 training [time: 0.84s, train loss: 25.0489]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.26it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 57 evaluating [time: 0.35s, hit@10: 0.167199]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16719914802981894 min-hit@10:0.13815789473684212 min-rhit@10:9.552237882674577 pop-kl@10:0.0037541666682249964 rhit@10:10.390779379603229\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 4 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 58\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 173.64it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 58 training [time: 0.89s, train loss: 24.6749]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.88it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 58 evaluating [time: 0.34s, hit@10: 0.168264]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16826411075612355 min-hit@10:0.14473684210526316 min-rhit@10:9.679952497046896 pop-kl@10:0.0036857106336121727 rhit@10:10.534389679293684\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 5 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 59\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 181.92it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 59 training [time: 0.85s, train loss: 24.4660]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.01it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 59 evaluating [time: 0.34s, hit@10: 0.162939]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16293929712460065 min-hit@10:0.13815789473684212 min-rhit@10:9.486164756375292 pop-kl@10:0.0035267816473809367 rhit@10:9.969252534025246\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 6 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 60\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 182.11it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 60 training [time: 0.85s, train loss: 24.2444]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.89it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 60 evaluating [time: 0.29s, hit@10: 0.166134]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16613418530351437 min-hit@10:0.13815789473684212 min-rhit@10:9.486670756665038 pop-kl@10:0.0032923766551782654 rhit@10:10.259867391591541\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 7 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 61\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.70it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 61 training [time: 0.86s, train loss: 23.8852]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.40it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 61 evaluating [time: 0.32s, hit@10: 0.166134]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16613418530351437 min-hit@10:0.13157894736842105 min-rhit@10:8.935273264546487 pop-kl@10:0.0032102061006619334 rhit@10:10.353133878149276\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 8 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 62\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.09it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 62 training [time: 0.86s, train loss: 23.6856]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.34it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 62 evaluating [time: 0.32s, hit@10: 0.169329]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.16932907348242812 min-hit@10:0.14473684210526316 min-rhit@10:9.679952497046896 pop-kl@10:0.0027415497844740433 rhit@10:10.538841379256658\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 9 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 63\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 176.80it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 63 training [time: 0.87s, train loss: 23.4129]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.70it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 63 evaluating [time: 0.30s, hit@10: 0.174654]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.17465388711395102 min-hit@10:0.14473684210526316 min-rhit@10:9.935289626230878 pop-kl@10:0.002333252301934048 rhit@10:10.853645023245031\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 63 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 64\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 182.11it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 64 training [time: 0.85s, train loss: 23.0221]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.32it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 64 evaluating [time: 0.32s, hit@10: 0.172524]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.17252396166134185 min-hit@10:0.14473684210526316 min-rhit@10:9.846460907855423 pop-kl@10:0.002687410031581251 rhit@10:10.694878855373787\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 65\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.49it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 65 training [time: 0.86s, train loss: 22.7406]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.19it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 65 evaluating [time: 0.33s, hit@10: 0.174654]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.17465388711395102 min-hit@10:0.14473684210526316 min-rhit@10:9.846460907855423 pop-kl@10:0.002804033078915374 rhit@10:10.725484411775449\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 66\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.85it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 66 training [time: 0.86s, train loss: 22.4640]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.58it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 66 evaluating [time: 0.31s, hit@10: 0.176784]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.17678381256656017 min-hit@10:0.1513157894736842 min-rhit@10:10.076814801680962 pop-kl@10:0.0024016238395797966 rhit@10:10.965047745647446\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 66 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 67\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.98it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 67 training [time: 0.86s, train loss: 22.3129]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.39it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 67 evaluating [time: 0.32s, hit@10: 0.173589]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.17358892438764642 min-hit@10:0.1513157894736842 min-rhit@10:10.076814801680962 pop-kl@10:0.0025624811897087723 rhit@10:10.768726313745047\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 68\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 180.90it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 68 training [time: 0.85s, train loss: 21.9216]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.53it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 68 evaluating [time: 0.31s, hit@10: 0.178914]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.17891373801916932 min-hit@10:0.14473684210526316 min-rhit@10:9.935289626230878 pop-kl@10:0.002347553706164935 rhit@10:11.208064017763173\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 68 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 69\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 174.95it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 69 training [time: 0.88s, train loss: 21.6926]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.15it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 69 evaluating [time: 0.33s, hit@10: 0.175719]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.1757188498402556 min-hit@10:0.13815789473684212 min-rhit@10:9.269815530035162 pop-kl@10:0.002608109184297284 rhit@10:10.901965110368833\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 70\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 180.55it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 70 training [time: 0.85s, train loss: 21.6198]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.03it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 70 evaluating [time: 0.34s, hit@10: 0.178914]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.17891373801916932 min-hit@10:0.13157894736842105 min-rhit@10:9.064567306043083 pop-kl@10:0.002799462798823549 rhit@10:11.10034741784446\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 71\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 182.08it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 71 training [time: 0.85s, train loss: 21.3421]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.39it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 71 evaluating [time: 0.32s, hit@10: 0.178914]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.17891373801916932 min-hit@10:0.13157894736842105 min-rhit@10:9.064567306043083 pop-kl@10:0.002713977160330165 rhit@10:11.0546948937683\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 72\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 176.27it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 72 training [time: 0.88s, train loss: 21.1349]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.16it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 72 evaluating [time: 0.39s, hit@10: 0.178914]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.17891373801916932 min-hit@10:0.13157894736842105 min-rhit@10:9.064567306043083 pop-kl@10:0.003033483257766627 rhit@10:11.005574097425288\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 4 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 73\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 181.30it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 73 training [time: 0.85s, train loss: 20.8644]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  7.08it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 73 evaluating [time: 0.29s, hit@10: 0.177849]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.17784877529286475 min-hit@10:0.13157894736842105 min-rhit@10:8.935273264546487 pop-kl@10:0.0027726137792131395 rhit@10:10.889894525702871\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 5 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 74\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.84it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 74 training [time: 0.86s, train loss: 20.5170]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.68it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 74 evaluating [time: 0.30s, hit@10: 0.182109]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.18210862619808307 min-hit@10:0.13815789473684212 min-rhit@10:9.423059097772002 pop-kl@10:0.0028548027739764073 rhit@10:11.246599953407172\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 74 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 75\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 177.57it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 75 training [time: 0.87s, train loss: 20.4664]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.02it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 75 evaluating [time: 0.34s, hit@10: 0.184239]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.18423855165069222 min-hit@10:0.13157894736842105 min-rhit@10:8.811746684747579 pop-kl@10:0.0026271293805507365 rhit@10:11.324078817658325\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 75 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 76\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.10it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 76 training [time: 0.87s, train loss: 20.2450]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.59it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 76 evaluating [time: 0.31s, hit@10: 0.186368]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.18636847710330137 min-hit@10:0.14473684210526316 min-rhit@10:9.628307321764082 pop-kl@10:0.0024182682955701793 rhit@10:11.449060092471129\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 76 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 77\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.11it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 77 training [time: 0.86s, train loss: 20.0518]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.77it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 77 evaluating [time: 0.35s, hit@10: 0.182109]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.18210862619808307 min-hit@10:0.1513157894736842 min-rhit@10:10.032988001950498 pop-kl@10:0.0021039724003390236 rhit@10:11.29558955072109\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 78\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.86it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 78 training [time: 0.86s, train loss: 19.8206]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.18it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 78 evaluating [time: 0.39s, hit@10: 0.184239]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.18423855165069222 min-hit@10:0.1513157894736842 min-rhit@10:10.140537850222959 pop-kl@10:0.002269060747366682 rhit@10:11.41852248380982\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 79\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 180.14it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 79 training [time: 0.86s, train loss: 19.5430]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.93it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 79 evaluating [time: 0.35s, hit@10: 0.183174]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.18317358892438765 min-hit@10:0.1513157894736842 min-rhit@10:10.140537850222959 pop-kl@10:0.002076191524145592 rhit@10:11.293749823475341\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 80\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 177.33it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 80 training [time: 0.87s, train loss: 19.4275]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.90it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 80 evaluating [time: 0.34s, hit@10: 0.184239]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.18423855165069222 min-hit@10:0.15789473684210525 min-rhit@10:10.34578607421504 pop-kl@10:0.002219334485661307 rhit@10:11.402871910795541\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 4 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 81\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.72it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 81 training [time: 0.86s, train loss: 19.2565]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.74it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 81 evaluating [time: 0.30s, hit@10: 0.185304]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.1853035143769968 min-hit@10:0.16447368421052633 min-rhit@10:10.84855299987765 pop-kl@10:0.0018838382545074647 rhit@10:11.476880480718837\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 5 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 82\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 180.71it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 82 training [time: 0.85s, train loss: 19.1105]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.09it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 82 evaluating [time: 0.33s, hit@10: 0.186368]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.18636847710330137 min-hit@10:0.15789473684210525 min-rhit@10:10.21869557466763 pop-kl@10:0.0016966269064079451 rhit@10:11.58618031449771\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 6 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 83\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.95it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 83 training [time: 0.86s, train loss: 18.9684]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.06it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 83 evaluating [time: 0.34s, hit@10: 0.181044]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.1810436634717785 min-hit@10:0.15789473684210525 min-rhit@10:10.34578607421504 pop-kl@10:0.0019532484320898564 rhit@10:11.175015810386896\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 7 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 84\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.10it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 84 training [time: 0.86s, train loss: 18.6337]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.88it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 84 evaluating [time: 0.34s, hit@10: 0.185304]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.1853035143769968 min-hit@10:0.15789473684210525 min-rhit@10:10.34578607421504 pop-kl@10:0.0019351839202508248 rhit@10:11.449577886510866\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 8 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 85\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.38it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 85 training [time: 0.87s, train loss: 18.6372]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  4.97it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 85 evaluating [time: 0.41s, hit@10: 0.187433]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.18743343982960597 min-hit@10:0.15789473684210525 min-rhit@10:10.34578607421504 pop-kl@10:0.0018689920407332782 rhit@10:11.571310481348636\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 85 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 86\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.29it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 86 training [time: 0.87s, train loss: 18.3451]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.34it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 86 evaluating [time: 0.32s, hit@10: 0.190628]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.1906283280085197 min-hit@10:0.16447368421052633 min-rhit@10:10.98972641444689 pop-kl@10:0.0015703839419380656 rhit@10:11.913612023992092\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 86 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 87\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 175.81it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 87 training [time: 0.88s, train loss: 18.2876]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.05it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 87 evaluating [time: 0.33s, hit@10: 0.187433]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.18743343982960597 min-hit@10:0.1513157894736842 min-rhit@10:9.734473661190615 pop-kl@10:0.0016312160082497733 rhit@10:11.555422667648283\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 88\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 177.45it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 88 training [time: 0.87s, train loss: 18.0970]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.74it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 88 evaluating [time: 0.35s, hit@10: 0.191693]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.19169329073482427 min-hit@10:0.16447368421052633 min-rhit@10:10.544922935547307 pop-kl@10:0.0015694985532908982 rhit@10:11.8164893018587\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 88 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 89\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.23it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 89 training [time: 0.86s, train loss: 17.9578]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.68it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 89 evaluating [time: 0.30s, hit@10: 0.189563]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.18956336528221512 min-hit@10:0.17105263157894737 min-rhit@10:10.544922935547307 pop-kl@10:0.001492484860295501 rhit@10:11.715557729162915\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 90\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 176.30it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 90 training [time: 0.88s, train loss: 17.7508]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.03it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 90 evaluating [time: 0.34s, hit@10: 0.192758]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.19275825346112885 min-hit@10:0.17105263157894737 min-rhit@10:10.908991583744294 pop-kl@10:0.0014025461731980346 rhit@10:11.954484074258158\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 90 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 91\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 181.79it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 91 training [time: 0.85s, train loss: 17.6624]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.36it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 91 evaluating [time: 0.32s, hit@10: 0.199148]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.19914802981895632 min-hit@10:0.1774891774891775 min-rhit@10:10.958454338596871 pop-kl@10:0.0014134269550961267 rhit@10:12.355577997506849\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 91 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 92\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.63it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 92 training [time: 0.86s, train loss: 17.4843]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.72it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 92 evaluating [time: 0.30s, hit@10: 0.197018]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.19701810436634717 min-hit@10:0.17105263157894737 min-rhit@10:11.288404607366877 pop-kl@10:0.0012234073595877365 rhit@10:12.132190856364229\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 93\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 177.63it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 93 training [time: 0.87s, train loss: 17.3004]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.11it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 93 evaluating [time: 0.33s, hit@10: 0.198083]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.19808306709265175 min-hit@10:0.17105263157894737 min-rhit@10:10.924335959169886 pop-kl@10:0.0015447627910004816 rhit@10:12.217042164438055\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 94\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.63it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 94 training [time: 0.86s, train loss: 17.2899]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.34it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 94 evaluating [time: 0.32s, hit@10: 0.195953]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.1959531416400426 min-hit@10:0.17105263157894737 min-rhit@10:10.955187810214182 pop-kl@10:0.0018028016867405218 rhit@10:12.093171075952734\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 95\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 178.60it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 95 training [time: 0.86s, train loss: 17.0218]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.22it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 95 evaluating [time: 0.33s, hit@10: 0.194888]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.19488817891373802 min-hit@10:0.17763157894736842 min-rhit@10:11.518758501192412 pop-kl@10:0.0018763657340235022 rhit@10:12.098334106234633\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 4 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 96\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 183.03it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 96 training [time: 0.84s, train loss: 16.9625]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.67it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 96 evaluating [time: 0.30s, hit@10: 0.195953]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.1959531416400426 min-hit@10:0.17763157894736842 min-rhit@10:11.002078609859764 pop-kl@10:0.0019928134371053775 rhit@10:12.03232615074383\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 5 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 97\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.76it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 97 training [time: 0.86s, train loss: 16.7636]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 97 evaluating [time: 0.31s, hit@10: 0.195953]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.1959531416400426 min-hit@10:0.17763157894736842 min-rhit@10:11.002078609859764 pop-kl@10:0.001490405675181293 rhit@10:12.07914363428923\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 6 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 98\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 177.66it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 98 training [time: 0.87s, train loss: 16.6703]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.02it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 98 evaluating [time: 0.34s, hit@10: 0.203408]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.20340788072417465 min-hit@10:0.17763157894736842 min-rhit@10:12.053354435024316 pop-kl@10:0.0014936021602110078 rhit@10:12.511718904065457\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 98 to /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 99\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 180.90it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 99 training [time: 0.85s, train loss: 16.6227]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.54it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 99 evaluating [time: 0.36s, hit@10: 0.201278]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.2012779552715655 min-hit@10:0.17763157894736842 min-rhit@10:12.053354435024316 pop-kl@10:0.0014894864126369107 rhit@10:12.443064384076148\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 100\n",
      "Train: 100%|██████████| 154/154 [00:00<00:00, 179.13it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 100 training [time: 0.86s, train loss: 16.4764]\n",
      "[INFO] MF-MoRec-Pretrain: Constructing dataset of task type: test\n",
      "[DEBUG] MF-MoRec-Pretrain: loading test at 25/10/2023 20:11:38\n",
      "[DEBUG] MF-MoRec-Pretrain: Finished loading test at 25/10/2023 20:11:38\n",
      "[INFO] MF-MoRec-Pretrain: Finished initializing <class 'unirec.data.dataset.basedataset.BaseDataset'>\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "[INFO] MF-MoRec-Pretrain: Loading model from /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth. The best epoch was 98\n",
      "Evaluate: 100%|██████████| 10/10 [00:00<00:00, 19.91it/s]\n",
      "[INFO] MF-MoRec-Pretrain: best valid : {'hit@10': 0.20340788072417465, 'rhit@10': 12.511718904065457, 'pop-kl@10': 0.0014936021602110078, 'min-hit@10': 0.17763157894736842, 'min-rhit@10': 12.053354435024316}\n",
      "[INFO] MF-MoRec-Pretrain: test result: {'hit@10': 0.15335463258785942, 'rhit@10': 8.945560041904715, 'pop-kl@10': 0.0014158862010865995, 'min-hit@10': 0.09032258064516129, 'min-rhit@10': 4.952566997895631}\n",
      "[INFO] MF-MoRec-Pretrain: Saving test result to /home/v-huangxu/.unirec/output/result_MF-MoRec-Pretrain.2023-10-25_200935.85.tsv ...\n",
      "[INFO] MF-MoRec-Pretrain: Mission complete. Time elapsed: 2.06 minutes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger close successfully.\n",
      "{'hit@10': 0.15335463258785942, 'rhit@10': 8.945560041904715, 'pop-kl@10': 0.0014158862010865995, 'min-hit@10': 0.09032258064516129, 'min-rhit@10': 4.952566997895631}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for arg in sys.argv:  # arguments conflict in notebooks, this is only required in notebooks\n",
    "    if \"-f\" in arg:\n",
    "        sys.argv.remove(arg)\n",
    "\n",
    "from unirec.main import main\n",
    "\n",
    "pretrain_config = deepcopy(GLOBAL_CONF)\n",
    "\n",
    "pretrain_config['checkpoint_dir'] = 'morec_pretrain_' + pretrain_config['checkpoint_dir']\n",
    "pretrain_config['exp_name'] = \"MoRec-Pretrain\"\n",
    "\n",
    "pretrain_result = main.run(pretrain_config)\n",
    "\n",
    "print(pretrain_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MoRec fine-tuning stage: multi-objective model tuning\n",
    "\n",
    "In this stage, the pretrained model is loaded and then trained successively toward a multi-objective model. \n",
    "\n",
    "Here we only need to set parameters for MoRec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] MF-Morec-Finetune: config={'gpu_id': 0, 'use_gpu': True, 'seed': 2022, 'state': 'INFO', 'verbose': 2, 'saved': True, 'use_tensorboard': False, 'use_wandb': False, 'init_method': 'normal', 'init_std': 0.02, 'init_mean': 0.0, 'scheduler': None, 'scheduler_factor': 0.1, 'time_seq': 0, 'seq_last': False, 'has_user_emb': True, 'has_user_bias': 0, 'has_item_bias': 0, 'use_features': False, 'use_text_emb': False, 'use_position_emb': True, 'load_pretrained_model': False, 'embedding_size': 32, 'hidden_size': 128, 'inner_size': 128, 'dropout_prob': 0.0, 'epochs': 10, 'batch_size': 512, 'learning_rate': 0.001, 'optimizer': 'adam', 'eval_step': 1, 'early_stop': -1, 'clip_grad_norm': None, 'weight_decay': 1e-06, 'num_workers': 4, 'persistent_workers': False, 'pin_memory': False, 'shuffle_train': False, 'use_pre_item_emb': 0, 'loss_type': 'bpr', 'ccl_w': 150, 'ccl_m': 0.4, 'distance_type': 'dot', 'metrics': \"['hit@10', 'rhit@10', 'pop-kl@10', 'least-misery']\", 'key_metric': 'hit@10', 'test_protocol': 'one_vs_all', 'valid_protocol': 'one_vs_all', 'test_batch_size': 100, 'model': 'MF', 'dataloader': 'BaseDataset', 'max_seq_len': 10, 'history_mask_mode': 'autoagressive', 'tau': 1.0, 'enable_morec': 1, 'morec_objectives': ['fairness', 'alignment', 'revenue'], 'morec_objective_controller': 'PID', 'morec_ngroup': 10, 'morec_alpha': 0.01, 'morec_lambda': 0.2, 'morec_expect_loss': 0.25, 'morec_beta_min': 0.1, 'morec_beta_max': 1.5, 'morec_K_p': 0.05, 'morec_K_i': 0.001, 'morec_objective_weights': '[0.1,0.1,0.8]', 'group_size': -1, 'n_items': 1017, 'n_neg_test_from_sampling': 0, 'n_neg_train_from_sampling': 0, 'n_neg_valid_from_sampling': 0, 'n_users': 940, 'test_file_format': 'user-item', 'train_file_format': 'user-item', 'user_history_file_format': 'user-item_seq', 'valid_file_format': 'user-item', 'config_dir': '/anaconda/envs/unirec/lib/python3.9/site-packages/unirec/config', 'exp_name': 'MF-Morec-Finetune', 'checkpoint_dir': 'morec_finetune_2023-10-25_20-09-34', 'dataset': 'ml-100k', 'dataset_path': '/home/v-huangxu/.unirec/dataset/binary/ml-100k', 'output_path': '/home/v-huangxu/.unirec/output', 'user_pre_item_emb': 0, 'n_sample_neg_train': 4, 'grad_clip_value': 0.1, 'user_history_filename': 'user_history', 'num_workers_test': 0, 'neg_by_pop_alpha': 0, 'item_meta_morec_filename': 'item_meta_morec.csv', 'align_dist_filename': None, 'model_file': '/home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth', 'cmd_args': {'config_dir': '/anaconda/envs/unirec/lib/python3.9/site-packages/unirec/config', 'exp_name': 'MF-Morec-Finetune', 'checkpoint_dir': 'morec_finetune_2023-10-25_20-09-34', 'model': 'MF', 'dataloader': 'BaseDataset', 'dataset': 'ml-100k', 'dataset_path': '/home/v-huangxu/.unirec/dataset/binary/ml-100k', 'output_path': '/home/v-huangxu/.unirec/output', 'learning_rate': 0.001, 'scheduler': None, 'dropout_prob': 0.0, 'embedding_size': 32, 'user_pre_item_emb': 0, 'loss_type': 'bpr', 'max_seq_len': 10, 'has_user_bias': 0, 'has_item_bias': 0, 'epochs': 10, 'early_stop': -1, 'batch_size': 512, 'n_sample_neg_train': 4, 'valid_protocol': 'one_vs_all', 'test_protocol': 'one_vs_all', 'grad_clip_value': 0.1, 'weight_decay': 1e-06, 'history_mask_mode': 'autoagressive', 'user_history_filename': 'user_history', 'metrics': \"['hit@10', 'rhit@10', 'pop-kl@10', 'least-misery']\", 'key_metric': 'hit@10', 'num_workers': 4, 'num_workers_test': 0, 'verbose': 2, 'neg_by_pop_alpha': 0, 'item_meta_morec_filename': 'item_meta_morec.csv', 'align_dist_filename': None, 'enable_morec': 1, 'model_file': '/home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth', 'morec_objectives': ['fairness', 'alignment', 'revenue'], 'morec_ngroup': 10, 'morec_alpha': 0.01, 'morec_lambda': 0.2, 'morec_expect_loss': 0.25, 'morec_beta_min': 0.1, 'morec_beta_max': 1.5, 'morec_K_p': 0.05, 'morec_K_i': 0.001, 'morec_objective_controller': 'PID', 'morec_objective_weights': '[0.1,0.1,0.8]', 'logger_time_str': '2023-10-25_201139', 'logger_rand': 61}, 'device': device(type='cuda'), 'task': 'train', 'logger_time_str': '2023-10-25_201139', 'logger_rand': 61}\n",
      "[INFO] MF-Morec-Finetune: Loading user history from user_history ...\n",
      "[INFO] MF-Morec-Finetune: Done. 940 of users have history.\n",
      "[INFO] MF-Morec-Finetune: Loading model from checkpoint: /home/v-huangxu/.unirec/output/morec_pretrain_2023-10-25_20-09-34/MF-MoRec-Pretrain.pth ...\n",
      "[INFO] MF-Morec-Finetune: Constructing dataset of task type: train\n",
      "[DEBUG] MF-Morec-Finetune: loading train at 25/10/2023 20:11:39\n",
      "[DEBUG] MF-Morec-Finetune: Finished loading train at 25/10/2023 20:11:39\n",
      "[INFO] MF-Morec-Finetune: Finished initializing <class 'unirec.data.dataset.basedataset.BaseDataset'>\n",
      "[INFO] MF-Morec-Finetune: Constructing dataset of task type: train\n",
      "[DEBUG] MF-Morec-Finetune: loading valid at 25/10/2023 20:11:39\n",
      "[DEBUG] MF-Morec-Finetune: Finished loading valid at 25/10/2023 20:11:39\n",
      "[INFO] MF-Morec-Finetune: Finished initializing <class 'unirec.data.dataset.basedataset.BaseDataset'>\n",
      "[INFO] MF-Morec-Finetune: Constructing dataset of task type: valid\n",
      "[DEBUG] MF-Morec-Finetune: loading valid at 25/10/2023 20:11:39\n",
      "[DEBUG] MF-Morec-Finetune: Finished loading valid at 25/10/2023 20:11:39\n",
      "[INFO] MF-Morec-Finetune: Finished initializing <class 'unirec.data.dataset.basedataset.BaseDataset'>\n",
      "[INFO] MF-Morec-Finetune: MF(\n",
      "  (scorer_layers): InnerProductScorer()\n",
      "  (user_embedding): Embedding(940, 32, padding_idx=0)\n",
      "  (item_embedding): Embedding(1017, 32, padding_idx=0)\n",
      ")\n",
      "Trainable parameter number: 62624\n",
      "All trainable parameters:\n",
      "user_embedding.weight : torch.Size([940, 32])\n",
      "item_embedding.weight : torch.Size([1017, 32])\n",
      "[DEBUG] MF-Morec-Finetune: >> Valid before training...\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load configuration files from /anaconda/envs/unirec/lib/python3.9/site-packages/unirec/config\n",
      "Writing logs to /home/v-huangxu/.unirec/output/MF-Morec-Finetune.2023-10-25_201139.61.txt\n",
      "static weight: [0.1, 0.1, 0.8].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.06it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 0 evaluating [time: 0.33s, hit@10: 0.203408]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.20340788072417465 min-hit@10:0.17763157894736842 min-rhit@10:12.053354435024316 pop-kl@10:0.0014936021602110078 rhit@10:12.511718904065457\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 0 to /home/v-huangxu/.unirec/output/morec_finetune_2023-10-25_20-09-34/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 1\n",
      "Train: 100%|██████████| 154/154 [00:03<00:00, 40.42it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 1 training [time: 3.81s, train loss: 5.1587]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  7.04it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 1 evaluating [time: 0.30s, hit@10: 0.198083]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.19808306709265175 min-hit@10:0.17763157894736842 min-rhit@10:11.699364055209445 pop-kl@10:0.001834632038267229 rhit@10:12.336367983152083\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 1 to /home/v-huangxu/.unirec/output/morec_finetune_2023-10-25_20-09-34/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 2\n",
      "Train: 100%|██████████| 154/154 [00:03<00:00, 40.95it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 2 training [time: 3.76s, train loss: 4.8614]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.16it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 2 evaluating [time: 0.33s, hit@10: 0.202343]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.20234291799787008 min-hit@10:0.18421052631578946 min-rhit@10:11.973610701555721 pop-kl@10:0.001809221729381515 rhit@10:12.700988434015338\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 2 to /home/v-huangxu/.unirec/output/morec_finetune_2023-10-25_20-09-34/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 3\n",
      "Train: 100%|██████████| 154/154 [00:03<00:00, 40.63it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 3 training [time: 3.79s, train loss: 4.8691]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.46it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 3 evaluating [time: 0.31s, hit@10: 0.198083]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.19808306709265175 min-hit@10:0.17763157894736842 min-rhit@10:11.934512237077055 pop-kl@10:0.0015688930220741637 rhit@10:12.54339493028695\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 3 to /home/v-huangxu/.unirec/output/morec_finetune_2023-10-25_20-09-34/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 4\n",
      "Train: 100%|██████████| 154/154 [00:03<00:00, 40.90it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 4 training [time: 3.77s, train loss: 4.8139]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.70it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 4 evaluating [time: 0.30s, hit@10: 0.200213]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.20021299254526093 min-hit@10:0.17763157894736842 min-rhit@10:11.614520350183014 pop-kl@10:0.0022946584289706903 rhit@10:12.796312272631983\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 4 to /home/v-huangxu/.unirec/output/morec_finetune_2023-10-25_20-09-34/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 5\n",
      "Train: 100%|██████████| 154/154 [00:03<00:00, 41.41it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 5 training [time: 3.72s, train loss: 4.7894]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.09it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 5 evaluating [time: 0.33s, hit@10: 0.193823]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.19382321618743345 min-hit@10:0.17105263157894737 min-rhit@10:11.729431877041007 pop-kl@10:0.002425682054827823 rhit@10:12.325427832626072\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 5 to /home/v-huangxu/.unirec/output/morec_finetune_2023-10-25_20-09-34/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 6\n",
      "Train: 100%|██████████| 154/154 [00:03<00:00, 41.21it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 6 training [time: 3.74s, train loss: 4.7632]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.66it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 6 evaluating [time: 0.30s, hit@10: 0.201278]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.2012779552715655 min-hit@10:0.17105263157894737 min-rhit@10:12.140734884248838 pop-kl@10:0.0024671279543365503 rhit@10:12.901774548024024\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 6 to /home/v-huangxu/.unirec/output/morec_finetune_2023-10-25_20-09-34/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 7\n",
      "Train: 100%|██████████| 154/154 [00:03<00:00, 41.83it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 7 training [time: 3.68s, train loss: 4.7164]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  5.99it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 7 evaluating [time: 0.34s, hit@10: 0.195953]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.1959531416400426 min-hit@10:0.17763157894736842 min-rhit@10:11.829908528558516 pop-kl@10:0.0025167955548160044 rhit@10:12.476716417844685\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 7 to /home/v-huangxu/.unirec/output/morec_finetune_2023-10-25_20-09-34/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 8\n",
      "Train: 100%|██████████| 154/154 [00:03<00:00, 41.81it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 8 training [time: 3.69s, train loss: 4.6922]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.76it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 8 evaluating [time: 0.30s, hit@10: 0.201278]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.2012779552715655 min-hit@10:0.18421052631578946 min-rhit@10:12.163125325711208 pop-kl@10:0.0026975484654752618 rhit@10:12.841892542876852\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 8 to /home/v-huangxu/.unirec/output/morec_finetune_2023-10-25_20-09-34/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 9\n",
      "Train: 100%|██████████| 154/154 [00:03<00:00, 41.45it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 9 training [time: 3.72s, train loss: 4.6700]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 2/2 [00:00<00:00,  6.02it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 9 evaluating [time: 0.34s, hit@10: 0.199148]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.19914802981895632 min-hit@10:0.18421052631578946 min-rhit@10:11.621509654447932 pop-kl@10:0.002863972116344253 rhit@10:12.677567510528386\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 9 to /home/v-huangxu/.unirec/output/morec_finetune_2023-10-25_20-09-34/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 10\n",
      "Train: 100%|██████████| 154/154 [00:03<00:00, 41.84it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 10 training [time: 3.68s, train loss: 4.6186]\n",
      "[INFO] MF-Morec-Finetune: Constructing dataset of task type: test\n",
      "[DEBUG] MF-Morec-Finetune: loading test at 25/10/2023 20:12:19\n",
      "[DEBUG] MF-Morec-Finetune: Finished loading test at 25/10/2023 20:12:19\n",
      "[INFO] MF-Morec-Finetune: Finished initializing <class 'unirec.data.dataset.basedataset.BaseDataset'>\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "[INFO] MF-Morec-Finetune: Loading model from /home/v-huangxu/.unirec/output/morec_finetune_2023-10-25_20-09-34/MF-Morec-Finetune.pth. The best epoch was 9\n",
      "Evaluate: 100%|██████████| 10/10 [00:00<00:00, 20.53it/s]\n",
      "[INFO] MF-Morec-Finetune: best valid : {'hit@10': 0.19914802981895632, 'rhit@10': 12.677567510528386, 'pop-kl@10': 0.002863972116344253, 'min-hit@10': 0.18421052631578946, 'min-rhit@10': 11.621509654447932}\n",
      "[INFO] MF-Morec-Finetune: test result: {'hit@10': 0.1501597444089457, 'rhit@10': 9.260119967662664, 'pop-kl@10': 0.002535212338356239, 'min-hit@10': 0.0967741935483871, 'min-rhit@10': 5.953895543650172}\n",
      "[INFO] MF-Morec-Finetune: Saving test result to /home/v-huangxu/.unirec/output/result_MF-Morec-Finetune.2023-10-25_201139.61.tsv ...\n",
      "[INFO] MF-Morec-Finetune: Mission complete. Time elapsed: 0.69 minutes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger close successfully.\n"
     ]
    }
   ],
   "source": [
    "# MoRec multi-objective post-training (fine-tuning) stage \n",
    "morec_config = deepcopy(GLOBAL_CONF)\n",
    "\n",
    "morec_config['enable_morec'] = 1\n",
    "morec_config['exp_name'] = 'Morec-Finetune'\n",
    "\n",
    "# pretrained model file is loaded by the `model_file` argument\n",
    "morec_config['model_file'] = os.path.join(pretrain_config['output_path'], pretrain_config['checkpoint_dir'], f\"{pretrain_config['model']}-{pretrain_config['exp_name']}.pth\")\n",
    "morec_config['checkpoint_dir'] = \"morec_finetune_\" + morec_config['checkpoint_dir']\n",
    "\n",
    "# MoRec parameters\n",
    "morec_config['morec_objectives']=['fairness', 'alignment', 'revenue']\n",
    "morec_config[\"morec_ngroup\"] = 10\n",
    "morec_config[\"morec_alpha\"] = 0.01\n",
    "morec_config[\"morec_lambda\"] = 0.2\n",
    "morec_config[\"morec_expect_loss\"] = 0.25\n",
    "morec_config[\"morec_beta_min\"] = 0.1\n",
    "morec_config[\"morec_beta_max\"] = 1.5\n",
    "morec_config[\"morec_K_p\"] = 0.05\n",
    "morec_config[\"morec_K_i\"] = 0.001\n",
    "morec_config[\"morec_objective_controller\"] = \"PID\"\n",
    "morec_config[\"morec_objective_weights\"] = \"[0.1,0.1,0.8]\"\n",
    "\n",
    "morec_config[\"epochs\"] = 10\n",
    "morec_config[\"early_stop\"] = -1\n",
    "\n",
    "morec_result = main.run(morec_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Comparisons\n",
    "\n",
    "The MoRec framework could improve model's performance in rhit@10, pop-kl@10, min-hit@10, which represent revenue, alignment and fairness respectively. And the improvements only sacrificy little accuracy, resulting in a 2.08% relative drop in term of hit@10. \n",
    "\n",
    "Note, the details of metrics used here are given in our [paper](https://arxiv.org/abs/2310.13260v1). The higher metrics represent the better performance, except the pop-kl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain:  {'hit@10': 0.15335463258785942, 'rhit@10': 8.945560041904715, 'pop-kl@10': 0.0014158862010865995, 'min-hit@10': 0.09032258064516129, 'min-rhit@10': 4.952566997895631}\n",
      "Finetune:  {'hit@10': 0.1501597444089457, 'rhit@10': 9.260119967662664, 'pop-kl@10': 0.002535212338356239, 'min-hit@10': 0.0967741935483871, 'min-rhit@10': 5.953895543650172}\n"
     ]
    }
   ],
   "source": [
    "print(\"Pretrain: \", pretrain_result)\n",
    "print(\"Finetune: \", morec_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unirec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
