{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation.</i>\n",
    "\n",
    "<i>Licensed under the MIT license.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoRec: A Data-Centric Multi-Objective Learning Framework for Responsible Recommendation Systems\n",
    "\n",
    "MoRec[[1]](https://arxiv.org/abs/2310.13260v1) is a data-centric multi-objective framework designed for responsible recommendation systems. Concretely, MoRec adopts a tri-level framework to optimize diverse objectives simultaneously, comprising a PID-based objective coordinator for trade-off among objectives and an adaptive data sampler for unified objective modeling. \n",
    "\n",
    "\n",
    "## Strengths of MoRec\n",
    "- MoRec is model-agnostic, which is capable of converting an accuracy-oriented model to multi-objective model\n",
    "- MoRec adopts a post-training strategy, which is able to convert a well-trained model to multi-objective model at a low cost\n",
    "- MoRec exhibit great capability in objective controlling, which could optimize model with objective preference without sacrificing too much accuracy\n",
    "\n",
    "## Data requirements\n",
    "\n",
    "MoRec is capable of optimizing accuracy, revenue, fairness and alignment objectives simultaneously. \n",
    "\n",
    "- For accuracy, basical user-item interaction files are required, including `train.csv`, `valid.csv`, `test.csv` and `user_history.csv`. \n",
    "  `train.csv`, `valid.csv`, `test.csv` represent interactions in training set, validation set and test set respectively, which are formatted as follows:\n",
    "\n",
    "  <table>\n",
    "      <tr>\n",
    "          <td>user_id</td>\n",
    "          <td>item_id</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>1</td>\n",
    "          <td>1</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>1</td>\n",
    "          <td>2</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>...</td>\n",
    "          <td>...</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>100</td>\n",
    "          <td>254</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>...</td>\n",
    "          <td>...</td>\n",
    "      </tr>\n",
    "  </table>\n",
    "\n",
    "  `user_history.csv` represents the user's interaction history, consist of interactions in training set and validation set, which is formatted as follows:\n",
    "\n",
    "  <table>\n",
    "      <tr>\n",
    "          <td>user_id</td>\n",
    "          <td>item_seq</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>1</td>\n",
    "          <td>1,2,3,...</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>...</td>\n",
    "          <td>...</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>100</td>\n",
    "          <td>254,257,327,...</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>...</td>\n",
    "          <td>...</td>\n",
    "      </tr>\n",
    "  </table>\n",
    "\n",
    "- For revenue, MoRec would sample data samples according to their weights, i.e. item price. For fairness, MoRec aims to improve the accuracy preformance of the most disadvantaged group. For alignment, MoRec targets on aligning the model's distribution with some pre-defined expectation distribution. To model those objectives, `item_meta_morec_filename` is required to provide item weights, fairness group and alignment group. And if you want to set the pre-set distribution for alignment,  `align_dist_filename` is needed. By default, the expected distribution to aligned with is the distribution derived from the training set. Here are the example of item_meta_morec_file  and align_dist_file.\n",
    "  \n",
    "  - item_meta_morec_file: `item_meta_morec.csv`, columns separated by comma\n",
    "\n",
    "  <table>\n",
    "      <tr>\n",
    "          <td>item_id</td>\n",
    "          <td>weight</td>\n",
    "          <td>fair_group</td>\n",
    "          <td>align_group</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>1</td>\n",
    "          <td>2.35</td>\n",
    "          <td>1</td>\n",
    "          <td>2</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>2</td>\n",
    "          <td>63.21</td>\n",
    "          <td>5</td>\n",
    "          <td>1</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>...</td>\n",
    "          <td>...</td>\n",
    "          <td>...</td>\n",
    "          <td>...</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>100</td>\n",
    "          <td>5.89</td>\n",
    "          <td>5</td>\n",
    "          <td>4</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>...</td>\n",
    "          <td>...</td>\n",
    "          <td>...</td>\n",
    "          <td>...</td>\n",
    "      </tr>\n",
    "  </table>\n",
    "\n",
    "  - align_dist_file: `expected_align_dist.csv`, columns separated by comma\n",
    "\n",
    "  <table>\n",
    "      <tr>\n",
    "          <td>group_id</td>\n",
    "          <td>proportion</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>1</td>\n",
    "          <td>0.21</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>2</td>\n",
    "          <td>0.12</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>3</td>\n",
    "          <td>0.33</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>4</td>\n",
    "          <td>0.22</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>5</td>\n",
    "          <td>0.12</td>\n",
    "      </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Amazon Electronics dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation\n",
    "\n",
    "We put the script for downloading and preprocessing ml-100k into the our [example folder](../../preprocess/download_split_ml100k.py). Here we would call the functions defined in the script. The preprocessed csv files would be saved in `~/.unirec/dataset/ml-100k`. \n",
    "\n",
    "We believe that you could easily process your own dataset to obtain `train.csv`, `valid.csv`, `test.csv` and `user_history.csv` using leave-one-out strategy. \n",
    "\n",
    "As for the columns in `item_meta_morec.csv` file, we set price of items as weight and group items according to their categories as the fair_group. As for align_group, we divide items according to the popularity, where items with similar popularity are put into the same group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "from copy import deepcopy\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../\"))\n",
    "from preprocess.download_split_amazon import preprocess_amazon\n",
    "from preprocess.prepare_data import process_transaction_dataset\n",
    "\n",
    "import unirec\n",
    "from unirec.main import main\n",
    "from unirec.constants.protocols import DataFileFormat\n",
    "\n",
    "UNIREC_PATH = os.path.dirname(unirec.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/anaconda/envs/unirec/lib/python3.9/site-packages/unirec'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNIREC_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset size: (7824482, 9)\n",
      "filter by rating>3 dataset size: (5833322, 9)\n",
      "drop_duplicates dataset size: (5833322, 9)\n",
      "Ite: 0, users: 177149 / 3256144, items: 51997 / 410110\n",
      "Ite: 1, users: 130234 / 177149, items: 45697 / 51997\n",
      "Ite: 2, users: 125581 / 130234, items: 44973 / 45697\n",
      "Ite: 3, users: 125011 / 125581, items: 44866 / 44973\n",
      "Ite: 4, users: 124916 / 125011, items: 44847 / 44866\n",
      "k-core filtered dataset size: (1072840, 9)\n",
      "#Users: 124916, #Items: 44847\n",
      "size in Train/Valid/Test: (823008, 2) / (124916, 2) / (124916, 2)\n",
      "0 raws price not float\n",
      "44847/44847 item prices existing in meta df\n",
      "Map dict saved in /home/v-huangxu/.unirec/dataset/Electronics/map.json.\n",
      "Item meta file saved in /home/v-huangxu/.unirec/dataset/Electronics/item_meta_morec.csv.\n"
     ]
    }
   ],
   "source": [
    "preprocess_amazon(\"Electronics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary Data File Preparation\n",
    "\n",
    "Upon the interaction files are processed, UniRec requires to convert them into binary files for time-saving loading. We provide the tools in [example folder](../../preprocess/prepare_data.py) to easily obtain the pickle file.\n",
    "\n",
    "Note that the function `process_transaction_dataset` requires some meta information of the csv files, such as the directory path, the seperator, header , file format and so on. \n",
    "\n",
    "Note that we have defined several data formats in UniRec, you can list all formats using codes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFileFormat.T1: user-item\n",
      "DataFileFormat.T2: user-item-label\n",
      "DataFileFormat.T2_1: user-item-label-session\n",
      "DataFileFormat.T3: user-item-rating\n",
      "DataFileFormat.T4: user-item_group-label_group\n",
      "DataFileFormat.T5: user-item_seq\n",
      "DataFileFormat.T5_1: user_item_seq\n",
      "DataFileFormat.T6: user-item_seq-time_seq\n",
      "DataFileFormat.T7: label-index_group-value_group\n"
     ]
    }
   ],
   "source": [
    "# All supported data file formats\n",
    "for format in DataFileFormat.__members__.values():\n",
    "    print(f\"{format}: {format.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_data_folder_path = os.path.expanduser(\"~/.unirec/dataset/binary/\")\n",
    "\n",
    "UNIREC_PATH = os.path.dirname(unirec.__file__)\n",
    "\n",
    "BINARY_FILE_CONFIG = {\n",
    "    \"raw_datapath\": os.path.expanduser(\"~/.unirec/dataset/Electronics\"), # the dir of csv files\n",
    "    \"outpathroot\": binary_data_folder_path, # the output dir of processed binary files\n",
    "    \"dataset_name\": \"Electronics\", # the dataset name, set as you like\n",
    "    \"example_yaml_file\": os.path.join(UNIREC_PATH, \"config/dataset/example.yaml\"), # Do not modify the value\n",
    "    \"index_by_zero\": 0,  # whether the user_id and item_id start from 0\n",
    "    \"sep\": \"\\t\" ,   # the seperator of csv files \n",
    "    \"train_file\": 'train.csv',  # the filename of training csv file\n",
    "    \"train_file_format\": 'user-item', \n",
    "    \"train_file_has_header\": 1, # whether the training file has header\n",
    "    \"train_file_col_names\": \"['user_id', 'item_id']\",  # the columns of training csv file\n",
    "    \"train_neg_k\": 0,  \n",
    "    \"valid_file\": 'valid.csv', # the filename of validation csv file\n",
    "    \"valid_file_format\": 'user-item', \n",
    "    \"valid_file_has_header\": 1, # whether the validation file has header\n",
    "    \"valid_file_col_names\": \"['user_id', 'item_id']\", # the columns of validation csv file\n",
    "    \"valid_neg_k\": 0, \n",
    "    \"test_file\": 'test.csv', # the filename of test csv file\n",
    "    \"test_file_format\": 'user-item', \n",
    "    \"test_file_has_header\": 1, # whether the test file has header\n",
    "    \"test_file_col_names\": \"['user_id', 'item_id']\", # the columns of test csv file\n",
    "    \"test_neg_k\": 0, \n",
    "    \"user_history_file\": 'user_history.csv', # the filename of history csv file\n",
    "    \"user_history_file_format\": 'user-item_seq', \n",
    "    \"user_history_file_has_header\": 1, # whether the history file has header\n",
    "    \"user_history_file_col_names\": \"['user_id', 'item_seq']\" # the columns of history csv file\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape of train.csv is (823008, 2)\n",
      "data dtypes is user_id    int64\n",
      "item_id    int64\n",
      "dtype: object\n",
      "saving train.pkl at 26/10/2023 17:29:16\n",
      "finish saving train.pkl at 26/10/2023 17:29:16\n",
      "In saving:\n",
      "   user_id  item_id\n",
      "0        1        1\n",
      "1        1        2\n",
      "2        1        3\n",
      "3        1        4\n",
      "4        2        7\n",
      "data.shape=(823008, 2)\n",
      "\n",
      "data shape of valid.csv is (124916, 2)\n",
      "data dtypes is user_id    int64\n",
      "item_id    int64\n",
      "dtype: object\n",
      "saving valid.pkl at 26/10/2023 17:29:16\n",
      "finish saving valid.pkl at 26/10/2023 17:29:16\n",
      "In saving:\n",
      "   user_id  item_id\n",
      "0        1        5\n",
      "1        2       10\n",
      "2        3       17\n",
      "3        4       23\n",
      "4        5       29\n",
      "data.shape=(124916, 2)\n",
      "\n",
      "data shape of test.csv is (124916, 2)\n",
      "data dtypes is user_id    int64\n",
      "item_id    int64\n",
      "dtype: object\n",
      "saving test.pkl at 26/10/2023 17:29:16\n",
      "finish saving test.pkl at 26/10/2023 17:29:16\n",
      "In saving:\n",
      "   user_id  item_id\n",
      "0        1        6\n",
      "1        2       11\n",
      "2        3       18\n",
      "3        4       24\n",
      "4        5       30\n",
      "data.shape=(124916, 2)\n",
      "\n",
      "data shape of user_history.csv is (124916, 2)\n",
      "data dtypes is user_id      int64\n",
      "item_seq    object\n",
      "dtype: object\n",
      "saving user_history.pkl at 26/10/2023 17:29:17\n",
      "finish saving user_history.pkl at 26/10/2023 17:29:18\n",
      "In saving:\n",
      "   user_id                  item_seq\n",
      "0        1           [1, 2, 3, 4, 5]\n",
      "1        2             [7, 8, 9, 10]\n",
      "2        3  [12, 13, 14, 15, 16, 17]\n",
      "3        4      [19, 20, 21, 22, 23]\n",
      "4        5      [25, 26, 27, 28, 29]\n",
      "data.shape=(124916, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_transaction_dataset(BINARY_FILE_CONFIG)    # the binary files would be saved in `binary_data_folder_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/v-huangxu/.unirec/dataset/binary/Electronics/item_meta_morec.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the item_meta_morec.csv file, we copy it to the binary file path as well\n",
    "shutil.copyfile(os.path.join(BINARY_FILE_CONFIG['raw_datapath'], 'item_meta_morec.csv'), os.path.join(BINARY_FILE_CONFIG['outpathroot'], BINARY_FILE_CONFIG['dataset_name'], 'item_meta_morec.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MoRec pretraining stage: accuracy-oriented model training\n",
    "\n",
    "Since MoRec provides a post-training strategy to convert a single-objective model (usually an accuracy-oriented model) to a multi-objective model, we need to train the accuracy-oriented model first.\n",
    "\n",
    "1. First, setup morec_configurations, including hyperparameters, file paths.\n",
    "2. Second, training with unirec's user-friendly interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Electronics\"\n",
    "model = \"MF\"\n",
    "ckpt_output_path = os.path.expanduser(\"~/.unirec/output\")\n",
    "\n",
    "GLOBAL_CONF = {\n",
    "    'config_dir': f\"{os.path.join(UNIREC_PATH, 'config')}\",\n",
    "    'exp_name': '',\n",
    "    'checkpoint_dir': datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"),\n",
    "    'model': model,\n",
    "    'dataloader': 'BaseDataset',\n",
    "    'dataset': dataset,\n",
    "    'dataset_path': os.path.join(BINARY_FILE_CONFIG['outpathroot'], dataset),\n",
    "    'output_path': os.path.join(ckpt_output_path, dataset, model),\n",
    "    'learning_rate': 0.001,\n",
    "    'scheduler': None,\n",
    "    'dropout_prob': 0.0,\n",
    "    'embedding_size': 64,\n",
    "    'user_pre_item_emb': 0,\n",
    "    'loss_type': 'bpr',\n",
    "    'max_seq_len': 10,\n",
    "    'has_user_bias': 0,\n",
    "    'has_item_bias': 0,\n",
    "    'epochs': 200,\n",
    "    'early_stop': 10,\n",
    "    'batch_size': 512,\n",
    "    'valid_batch_size': 1024,\n",
    "    'n_sample_neg_train': 10,\n",
    "    'valid_protocol': 'one_vs_all',\n",
    "    'test_protocol': 'one_vs_all',\n",
    "    'grad_clip_value': -1,\n",
    "    'weight_decay': 1e-6,\n",
    "    'history_mask_mode': 'autoagressive',\n",
    "    'user_history_filename': \"user_history\",\n",
    "    'metrics': \"['hit@10', 'rhit@10', 'pop-kl@10', 'least-misery']\",\n",
    "    'key_metric': \"hit@10\",\n",
    "    'num_workers': 4,\n",
    "    'num_workers_test': 0,\n",
    "    'verbose': 2,\n",
    "    'neg_by_pop_alpha': 1.0,\n",
    "    'item_meta_morec_filename': 'item_meta_morec.csv',\n",
    "    'align_dist_filename': None,  # the expected alignment distribution is set as the distribution derived from the training set\n",
    "    'use_tensorboard': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load configuration files from /anaconda/envs/unirec/lib/python3.9/site-packages/unirec/config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] MF-MoRec-Pretrain: config={'gpu_id': 0, 'use_gpu': True, 'seed': 2022, 'state': 'INFO', 'verbose': 2, 'saved': True, 'use_tensorboard': 1, 'use_wandb': False, 'init_method': 'normal', 'init_std': 0.02, 'init_mean': 0.0, 'scheduler': None, 'scheduler_factor': 0.1, 'time_seq': 0, 'seq_last': False, 'has_user_emb': True, 'has_user_bias': 0, 'has_item_bias': 0, 'use_features': False, 'use_text_emb': False, 'use_position_emb': True, 'load_pretrained_model': False, 'embedding_size': 64, 'hidden_size': 128, 'inner_size': 128, 'dropout_prob': 0.0, 'epochs': 200, 'batch_size': 512, 'learning_rate': 0.001, 'optimizer': 'adam', 'eval_step': 1, 'early_stop': 10, 'clip_grad_norm': None, 'weight_decay': 1e-06, 'num_workers': 4, 'persistent_workers': False, 'pin_memory': False, 'shuffle_train': False, 'use_pre_item_emb': 0, 'loss_type': 'bpr', 'ccl_w': 150, 'ccl_m': 0.4, 'distance_type': 'dot', 'metrics': \"['hit@10', 'rhit@10', 'pop-kl@10', 'least-misery']\", 'key_metric': 'hit@10', 'test_protocol': 'one_vs_all', 'valid_protocol': 'one_vs_all', 'test_batch_size': 100, 'model': 'MF', 'dataloader': 'BaseDataset', 'max_seq_len': 10, 'history_mask_mode': 'autoagressive', 'tau': 1.0, 'enable_morec': 0, 'morec_objectives': ['fairness', 'alignment', 'revenue'], 'morec_objective_controller': 'PID', 'morec_ngroup': [10, 10, -1], 'morec_alpha': 0.1, 'morec_lambda': 0.2, 'morec_expect_loss': 0.2, 'morec_beta_min': 0.6, 'morec_beta_max': 1.3, 'morec_K_p': 0.01, 'morec_K_i': 0.001, 'morec_objective_weights': '[0.3,0.3,0.4]', 'group_size': -1, 'n_items': 44848, 'n_neg_test_from_sampling': 0, 'n_neg_train_from_sampling': 0, 'n_neg_valid_from_sampling': 0, 'n_users': 124917, 'test_file_format': 'user-item', 'train_file_format': 'user-item', 'user_history_file_format': 'user-item_seq', 'valid_file_format': 'user-item', 'config_dir': '/anaconda/envs/unirec/lib/python3.9/site-packages/unirec/config', 'exp_name': 'MF-MoRec-Pretrain', 'checkpoint_dir': 'morec_pretrain_2023-10-26_17-29-19', 'dataset': 'Electronics', 'dataset_path': '/home/v-huangxu/.unirec/dataset/binary/Electronics', 'output_path': '/home/v-huangxu/.unirec/output/Electronics/MF', 'user_pre_item_emb': 0, 'valid_batch_size': 1024, 'n_sample_neg_train': 10, 'grad_clip_value': -1, 'user_history_filename': 'user_history', 'num_workers_test': 0, 'neg_by_pop_alpha': 1.0, 'item_meta_morec_filename': 'item_meta_morec.csv', 'align_dist_filename': None, 'cmd_args': {'config_dir': '/anaconda/envs/unirec/lib/python3.9/site-packages/unirec/config', 'exp_name': 'MF-MoRec-Pretrain', 'checkpoint_dir': 'morec_pretrain_2023-10-26_17-29-19', 'model': 'MF', 'dataloader': 'BaseDataset', 'dataset': 'Electronics', 'dataset_path': '/home/v-huangxu/.unirec/dataset/binary/Electronics', 'output_path': '/home/v-huangxu/.unirec/output/Electronics/MF', 'learning_rate': 0.001, 'scheduler': None, 'dropout_prob': 0.0, 'embedding_size': 64, 'user_pre_item_emb': 0, 'loss_type': 'bpr', 'max_seq_len': 10, 'has_user_bias': 0, 'has_item_bias': 0, 'epochs': 200, 'early_stop': 10, 'batch_size': 512, 'valid_batch_size': 1024, 'n_sample_neg_train': 10, 'valid_protocol': 'one_vs_all', 'test_protocol': 'one_vs_all', 'grad_clip_value': -1, 'weight_decay': 1e-06, 'history_mask_mode': 'autoagressive', 'user_history_filename': 'user_history', 'metrics': \"['hit@10', 'rhit@10', 'pop-kl@10', 'least-misery']\", 'key_metric': 'hit@10', 'num_workers': 4, 'num_workers_test': 0, 'verbose': 2, 'neg_by_pop_alpha': 1.0, 'item_meta_morec_filename': 'item_meta_morec.csv', 'align_dist_filename': None, 'use_tensorboard': 1, 'logger_time_str': '2023-10-26_172919', 'logger_rand': 100}, 'device': device(type='cuda'), 'task': 'train', 'logger_time_str': '2023-10-26_172919', 'logger_rand': 100}\n",
      "[INFO] MF-MoRec-Pretrain: Loading user history from user_history ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing logs to /home/v-huangxu/.unirec/output/Electronics/MF/MF-MoRec-Pretrain.2023-10-26_172919.100.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] MF-MoRec-Pretrain: Done. 124917 of users have history.\n",
      "[INFO] MF-MoRec-Pretrain: Constructing dataset of task type: train\n",
      "[DEBUG] MF-MoRec-Pretrain: loading train at 26/10/2023 17:29:21\n",
      "[DEBUG] MF-MoRec-Pretrain: Finished loading train at 26/10/2023 17:29:21\n",
      "[INFO] MF-MoRec-Pretrain: Finished initializing <class 'unirec.data.dataset.basedataset.BaseDataset'>\n",
      "[INFO] MF-MoRec-Pretrain: Constructing dataset of task type: valid\n",
      "[DEBUG] MF-MoRec-Pretrain: loading valid at 26/10/2023 17:29:21\n",
      "[DEBUG] MF-MoRec-Pretrain: Finished loading valid at 26/10/2023 17:29:21\n",
      "[INFO] MF-MoRec-Pretrain: Finished initializing <class 'unirec.data.dataset.basedataset.BaseDataset'>\n",
      "[INFO] MF-MoRec-Pretrain: MF(\n",
      "  (scorer_layers): InnerProductScorer()\n",
      "  (user_embedding): Embedding(124917, 64, padding_idx=0)\n",
      "  (item_embedding): Embedding(44848, 64, padding_idx=0)\n",
      ")\n",
      "Trainable parameter number: 10864960\n",
      "All trainable parameters:\n",
      "user_embedding.weight : torch.Size([124917, 64])\n",
      "item_embedding.weight : torch.Size([44848, 64])\n",
      "[INFO] MF-MoRec-Pretrain: tensorboard log file saved in /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19\n",
      "[DEBUG] MF-MoRec-Pretrain: >> Valid before training...\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:25<00:00,  1.42it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 0 evaluating [time: 85.81s, hit@10: 0.000248]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.00024816676806814177 min-hit@10:0.0 min-rhit@10:0.0 pop-kl@10:0.6680214467375609 rhit@10:0.018153799353165325\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 0 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 1\n",
      "Train: 100%|██████████| 1608/1608 [00:10<00:00, 152.91it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 1 training [time: 10.52s, train loss: 1114.5808]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:16<00:00,  1.59it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 1 evaluating [time: 76.76s, hit@10: 0.001737]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.0017371673764769926 min-hit@10:0.0 min-rhit@10:0.0 pop-kl@10:0.3834596448731298 rhit@10:0.06344943802235102\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 1 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 2\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 165.66it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 2 training [time: 9.71s, train loss: 1112.6129]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:17<00:00,  1.57it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 2 evaluating [time: 77.75s, hit@10: 0.018020]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.018020109513593136 min-hit@10:0.0 min-rhit@10:0.0 pop-kl@10:5.674750620659745 rhit@10:0.7510887316276539\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 2 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 3\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 165.17it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 3 training [time: 9.74s, train loss: 1055.7458]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 3 evaluating [time: 81.04s, hit@10: 0.020686]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.020685900925421885 min-hit@10:0.0 min-rhit@10:0.0 pop-kl@10:6.482447908800175 rhit@10:1.1634314259182168\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 3 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 4\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 165.66it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 4 training [time: 9.71s, train loss: 947.3856]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:19<00:00,  1.53it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 4 evaluating [time: 79.77s, hit@10: 0.020870]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.020870024656569213 min-hit@10:0.0 min-rhit@10:0.0 pop-kl@10:6.5338076833429986 rhit@10:1.510981219379423\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 4 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 5\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 164.79it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 5 training [time: 9.76s, train loss: 838.9582]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:18<00:00,  1.55it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 5 evaluating [time: 78.63s, hit@10: 0.021510]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.021510455025777322 min-hit@10:0.0003627130939426913 min-rhit@10:0.0060210373594486765 pop-kl@10:6.589015419234851 rhit@10:1.7743720580229911\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 5 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 6\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 165.75it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 6 training [time: 9.70s, train loss: 742.3507]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:19<00:00,  1.54it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 6 evaluating [time: 79.38s, hit@10: 0.021550]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.021550481923852827 min-hit@10:0.001088139281828074 min-rhit@10:0.03353282553500181 pop-kl@10:6.638023581021681 rhit@10:1.8563408210317331\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 6 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 7\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 164.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 7 training [time: 9.78s, train loss: 657.8518]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 7 evaluating [time: 80.15s, hit@10: 0.020990]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.020990105350795735 min-hit@10:0.0029017047515415306 min-rhit@10:0.09145447950671019 pop-kl@10:5.778331765927806 rhit@10:1.8490716961798328\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 8\n",
      "Train: 100%|██████████| 1608/1608 [00:10<00:00, 157.75it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 8 training [time: 10.20s, train loss: 586.1568]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 8 evaluating [time: 80.29s, hit@10: 0.020846]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02084600851772391 min-hit@10:0.003989844033369605 min-rhit@10:0.11984766050054407 pop-kl@10:5.557146877464247 rhit@10:1.8389420890838646\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 9\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 164.83it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 9 training [time: 9.76s, train loss: 526.8066]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.48it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 9 evaluating [time: 82.58s, hit@10: 0.020798]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.0207979762400333 min-hit@10:0.005077983315197679 min-rhit@10:0.13803409503083064 pop-kl@10:4.321490547902395 rhit@10:1.8090617695091102\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 10\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.77it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 10 training [time: 9.82s, train loss: 478.9679]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.48it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 10 evaluating [time: 82.32s, hit@10: 0.020694]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.020693906305036983 min-hit@10:0.005803409503083061 min-rhit@10:0.1549220166848023 pop-kl@10:3.9632320752642816 rhit@10:1.8002283934804186\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 4 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 11\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 165.01it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 11 training [time: 9.75s, train loss: 441.1356]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:19<00:00,  1.54it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 11 evaluating [time: 79.18s, hit@10: 0.021142]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02114220756348266 min-hit@10:0.007254261878853826 min-rhit@10:0.18690605730866883 pop-kl@10:3.0420956711894624 rhit@10:1.822050417880816\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 5 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 12\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.74it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 12 training [time: 9.82s, train loss: 411.9941]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:19<00:00,  1.53it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 12 evaluating [time: 79.65s, hit@10: 0.021422]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.021422395850011208 min-hit@10:0.007254261878853826 min-rhit@10:0.19379760609357996 pop-kl@10:2.5416674563866026 rhit@10:1.9022463895737933\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 6 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 13\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 164.09it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 13 training [time: 9.80s, train loss: 388.7665]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:19<00:00,  1.54it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 13 evaluating [time: 79.46s, hit@10: 0.022183]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.022182906913445835 min-hit@10:0.00797968806673921 min-rhit@10:0.2245665578527385 pop-kl@10:2.7276133429651774 rhit@10:1.9634880239520958\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 13 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 14\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.16it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 14 training [time: 9.86s, train loss: 370.7000]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:19<00:00,  1.53it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 14 evaluating [time: 79.60s, hit@10: 0.022295]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.022294982228057255 min-hit@10:0.007616974972796518 min-rhit@10:0.21007616974972798 pop-kl@10:2.145120543486839 rhit@10:1.9579450190528036\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 14 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 15\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.13it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 15 training [time: 9.86s, train loss: 356.3612]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:19<00:00,  1.53it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 15 evaluating [time: 79.54s, hit@10: 0.022367]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.022367030644593167 min-hit@10:0.008705114254624592 min-rhit@10:0.2848277112803772 pop-kl@10:2.349626076747196 rhit@10:1.992711502129431\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 15 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 16\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.40it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 16 training [time: 9.90s, train loss: 345.1427]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:19<00:00,  1.54it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 16 evaluating [time: 79.43s, hit@10: 0.022695]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02269525120881232 min-hit@10:0.007616974972796518 min-rhit@10:0.24236488937250636 pop-kl@10:1.9377723129703486 rhit@10:2.010131208171891\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 16 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 17\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.16it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 17 training [time: 9.86s, train loss: 335.9074]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:18<00:00,  1.54it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 17 evaluating [time: 78.99s, hit@10: 0.022695]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02269525120881232 min-hit@10:0.008705114254624592 min-rhit@10:0.27622415669205663 pop-kl@10:2.165968354864943 rhit@10:1.986767587819014\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 18\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.63it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 18 training [time: 9.83s, train loss: 328.8635]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:19<00:00,  1.54it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 18 evaluating [time: 79.10s, hit@10: 0.023152]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.0231515578468731 min-hit@10:0.009067827348567283 min-rhit@10:0.2787123685165035 pop-kl@10:1.809598793265304 rhit@10:2.0491623170770756\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 18 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 19\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 164.53it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 19 training [time: 9.78s, train loss: 322.7937]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:19<00:00,  1.54it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 19 evaluating [time: 79.18s, hit@10: 0.023464]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02346376765186205 min-hit@10:0.011244105912223431 min-rhit@10:0.3877548059484947 pop-kl@10:1.910164556444878 rhit@10:2.0835519068814246\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 19 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 20\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 165.34it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 20 training [time: 9.73s, train loss: 317.8282]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 20 evaluating [time: 80.81s, hit@10: 0.023192]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.023191584744948604 min-hit@10:0.01088139281828074 min-rhit@10:0.3121508886470802 pop-kl@10:1.7423489180648408 rhit@10:2.072052179064331\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 21\n",
      "Train: 100%|██████████| 1608/1608 [00:10<00:00, 160.43it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 21 training [time: 10.03s, train loss: 313.9417]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.48it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 21 evaluating [time: 82.47s, hit@10: 0.023992]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02399212270645874 min-hit@10:0.011606819006166122 min-rhit@10:0.3634312658686979 pop-kl@10:1.6703932754591246 rhit@10:2.1782687566044383\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 21 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 22\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.15it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 22 training [time: 9.92s, train loss: 310.4167]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.48it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 22 evaluating [time: 82.37s, hit@10: 0.024288]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02428832175221749 min-hit@10:0.012332245194051506 min-rhit@10:0.39368153790351834 pop-kl@10:1.6117566986395258 rhit@10:2.164372218130584\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 22 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 23\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.55it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 23 training [time: 9.89s, train loss: 307.5884]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 23 evaluating [time: 80.56s, hit@10: 0.024216]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02421627333568158 min-hit@10:0.011244105912223431 min-rhit@10:0.33002176278563655 pop-kl@10:1.606911912518525 rhit@10:2.1672518332319317\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 24\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 164.06it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 24 training [time: 9.80s, train loss: 305.0636]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 24 evaluating [time: 80.15s, hit@10: 0.024304]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02430433251144769 min-hit@10:0.012332245194051506 min-rhit@10:0.35619876677548057 pop-kl@10:1.5433649289282096 rhit@10:2.198496509654488\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 24 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 25\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 164.43it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 25 training [time: 9.78s, train loss: 302.7984]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 25 evaluating [time: 80.74s, hit@10: 0.024577]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.024576515418361138 min-hit@10:0.012332245194051506 min-rhit@10:0.3753971708378673 pop-kl@10:1.5442751541509137 rhit@10:2.2088413814083063\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 25 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 26\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.82it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 26 training [time: 9.88s, train loss: 301.0760]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 26 evaluating [time: 80.48s, hit@10: 0.024825]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02482468218642928 min-hit@10:0.011606819006166122 min-rhit@10:0.32981138919114983 pop-kl@10:1.5108189650514352 rhit@10:2.2131995901245634\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 26 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 27\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 164.70it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 27 training [time: 9.77s, train loss: 299.5471]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 27 evaluating [time: 80.39s, hit@10: 0.024593]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02459252617759134 min-hit@10:0.012332245194051506 min-rhit@10:0.40776931447225245 pop-kl@10:1.5356545650155056 rhit@10:2.2073865637708536\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 28\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 164.34it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 28 training [time: 9.79s, train loss: 298.0129]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 28 evaluating [time: 80.62s, hit@10: 0.024585]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02458452079797624 min-hit@10:0.011606819006166122 min-rhit@10:0.3928908233587233 pop-kl@10:1.5345421348429984 rhit@10:2.2154903295014243\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 29\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.71it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 29 training [time: 9.82s, train loss: 296.7733]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 29 evaluating [time: 80.07s, hit@10: 0.025225]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02522495116718435 min-hit@10:0.01342038447587958 min-rhit@10:0.3822705839680813 pop-kl@10:1.5134715783462953 rhit@10:2.277717506164142\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 29 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 30\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.48it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 30 training [time: 9.84s, train loss: 295.5209]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 30 evaluating [time: 80.70s, hit@10: 0.025209]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.025208940407954145 min-hit@10:0.01342038447587958 min-rhit@10:0.368904606456293 pop-kl@10:1.4951446526216032 rhit@10:2.2964868391559126\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 31\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.72it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 31 training [time: 9.82s, train loss: 294.7189]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:19<00:00,  1.53it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 31 evaluating [time: 79.88s, hit@10: 0.025393]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.025393064139101477 min-hit@10:0.012332245194051506 min-rhit@10:0.3496953210010881 pop-kl@10:1.5158058499330473 rhit@10:2.313192145121522\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 31 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 32\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.66it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 32 training [time: 9.83s, train loss: 293.7883]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 32 evaluating [time: 80.06s, hit@10: 0.025393]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.025393064139101477 min-hit@10:0.014145810663764961 min-rhit@10:0.37868697859992745 pop-kl@10:1.4927887601437677 rhit@10:2.24622898587851\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 33\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.55it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 33 training [time: 9.89s, train loss: 292.9582]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 33 evaluating [time: 80.87s, hit@10: 0.025745]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.025745300842165936 min-hit@10:0.01342038447587958 min-rhit@10:0.3720239390642002 pop-kl@10:1.4828010977148711 rhit@10:2.323567277210285\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 33 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 34\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 164.08it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 34 training [time: 9.80s, train loss: 292.0784]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 34 evaluating [time: 80.36s, hit@10: 0.025497]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.025497134074097795 min-hit@10:0.01342038447587958 min-rhit@10:0.3700362713093943 pop-kl@10:1.4691385707978841 rhit@10:2.304882641134842\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 35\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.58it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 35 training [time: 9.89s, train loss: 291.6092]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 35 evaluating [time: 80.16s, hit@10: 0.025489]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.025489128694482693 min-hit@10:0.015596663039535727 min-rhit@10:0.45109176641276744 pop-kl@10:1.4765029719293168 rhit@10:2.271727560920939\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 36\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.86it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 36 training [time: 9.88s, train loss: 290.8187]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.50it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 36 evaluating [time: 81.19s, hit@10: 0.025513]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.025513144833327995 min-hit@10:0.014871236851650345 min-rhit@10:0.47484947406601374 pop-kl@10:1.4835831603767522 rhit@10:2.27697628806558\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 37\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.27it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 37 training [time: 9.85s, train loss: 290.3451]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 37 evaluating [time: 80.47s, hit@10: 0.025961]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02596144609177367 min-hit@10:0.014508523757707652 min-rhit@10:0.4251106274936525 pop-kl@10:1.4671573060879068 rhit@10:2.3277024560504658\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 37 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 38\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.25it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 38 training [time: 9.85s, train loss: 289.9489]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 38 evaluating [time: 80.37s, hit@10: 0.025673]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.025673252425630025 min-hit@10:0.015233949945593036 min-rhit@10:0.4807290533188249 pop-kl@10:1.2588238816777617 rhit@10:2.30471276697941\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 39\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.44it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 39 training [time: 9.84s, train loss: 289.3163]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 39 evaluating [time: 80.28s, hit@10: 0.025849]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.025849370777162255 min-hit@10:0.014871236851650345 min-rhit@10:0.42247007616974974 pop-kl@10:1.4367910253964171 rhit@10:2.3112472381440323\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 40\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.67it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 40 training [time: 9.83s, train loss: 288.9484]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 40 evaluating [time: 80.49s, hit@10: 0.026274]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.026273655896762626 min-hit@10:0.015233949945593036 min-rhit@10:0.4437141820819732 pop-kl@10:1.4345378370970483 rhit@10:2.3991669601972525\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 40 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 41\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.17it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 41 training [time: 9.86s, train loss: 288.4338]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 41 evaluating [time: 80.62s, hit@10: 0.026530]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02652982804444587 min-hit@10:0.014871236851650345 min-rhit@10:0.4840152339499456 pop-kl@10:1.4514857959359577 rhit@10:2.449571632136796\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 41 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 42\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.58it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 42 training [time: 9.89s, train loss: 288.1048]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:19<00:00,  1.53it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 42 evaluating [time: 79.85s, hit@10: 0.026450]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.026449774248294856 min-hit@10:0.014871236851650345 min-rhit@10:0.49007979688066733 pop-kl@10:1.4488973039062882 rhit@10:2.440043389157513\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 43\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.88it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 43 training [time: 9.87s, train loss: 287.7014]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:19<00:00,  1.53it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 43 evaluating [time: 79.98s, hit@10: 0.026370]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02636972045214384 min-hit@10:0.014871236851650345 min-rhit@10:0.45174102285092493 pop-kl@10:1.442843603095477 rhit@10:2.4334222197316597\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 44\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.91it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 44 training [time: 9.87s, train loss: 287.3407]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 44 evaluating [time: 80.37s, hit@10: 0.026546]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02654583880367607 min-hit@10:0.015596663039535727 min-rhit@10:0.5256795153034576 pop-kl@10:1.4305127381167175 rhit@10:2.4188076787601265\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 44 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 45\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.04it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 45 training [time: 9.86s, train loss: 287.1453]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 45 evaluating [time: 80.21s, hit@10: 0.026546]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02654583880367607 min-hit@10:0.015596663039535727 min-rhit@10:0.5277765687341314 pop-kl@10:1.4521402138749155 rhit@10:2.4419637196195842\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 46\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.46it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 46 training [time: 9.84s, train loss: 286.7380]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 46 evaluating [time: 80.08s, hit@10: 0.026554]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02655384418329117 min-hit@10:0.01603206412825651 min-rhit@10:0.5264791601378879 pop-kl@10:1.4415290025533078 rhit@10:2.4488259310256493\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 46 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 47\n",
      "Train: 100%|██████████| 1608/1608 [00:10<00:00, 155.76it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 47 training [time: 10.33s, train loss: 286.4417]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 47 evaluating [time: 80.40s, hit@10: 0.026722]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.0267219571552083 min-hit@10:0.014487079091620987 min-rhit@10:0.53858769455761 pop-kl@10:1.441704869662591 rhit@10:2.4392425309808194\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 47 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 48\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.59it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 48 training [time: 9.83s, train loss: 286.1886]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.49it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 48 evaluating [time: 81.78s, hit@10: 0.026898]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02689807550674053 min-hit@10:0.016760794315904538 min-rhit@10:0.5269169387014871 pop-kl@10:1.450300438075486 rhit@10:2.4977309552018956\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 48 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 49\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 160.92it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 49 training [time: 9.99s, train loss: 285.9134]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:23<00:00,  1.47it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 49 evaluating [time: 83.11s, hit@10: 0.026858]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.026858048608665024 min-hit@10:0.014145810663764961 min-rhit@10:0.45939789626405514 pop-kl@10:1.2225945081524072 rhit@10:2.491542236382849\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 50\n",
      "Train: 100%|██████████| 1608/1608 [00:10<00:00, 159.96it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 50 training [time: 10.06s, train loss: 285.7913]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.49it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 50 evaluating [time: 82.02s, hit@10: 0.027002]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027002145441736847 min-hit@10:0.015233949945593036 min-rhit@10:0.4991113529198405 pop-kl@10:1.2334721699651794 rhit@10:2.4467352460853693\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 50 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 51\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.01it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 51 training [time: 9.87s, train loss: 285.4682]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 51 evaluating [time: 80.66s, hit@10: 0.026730]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.0267299625348234 min-hit@10:0.014145810663764961 min-rhit@10:0.4288973521944142 pop-kl@10:1.2386783142477031 rhit@10:2.4458130263537097\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 52\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 164.10it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 52 training [time: 9.80s, train loss: 285.3864]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 52 evaluating [time: 80.32s, hit@10: 0.027010]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02701015082135195 min-hit@10:0.014145810663764961 min-rhit@10:0.39996372869060576 pop-kl@10:1.4236932345934195 rhit@10:2.457795878830574\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 52 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 53\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.08it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 53 training [time: 9.86s, train loss: 285.1192]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 53 evaluating [time: 80.40s, hit@10: 0.027042]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027042172339812355 min-hit@10:0.014508523757707652 min-rhit@10:0.4779361624954661 pop-kl@10:1.436631010002193 rhit@10:2.5100946235870505\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 53 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 54\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.13it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 54 training [time: 9.86s, train loss: 284.8838]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 54 evaluating [time: 80.71s, hit@10: 0.027010]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02701015082135195 min-hit@10:0.014871236851650345 min-rhit@10:0.478240841494378 pop-kl@10:1.4290294630977596 rhit@10:2.5141122034006855\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 55\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.19it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 55 training [time: 9.92s, train loss: 284.5510]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 55 evaluating [time: 80.57s, hit@10: 0.027066]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027066188478657657 min-hit@10:0.015233949945593036 min-rhit@10:0.5028616943486891 pop-kl@10:1.435612566012 rhit@10:2.4654772006788566\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 55 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 56\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.83it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 56 training [time: 9.82s, train loss: 284.5301]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 56 evaluating [time: 80.53s, hit@10: 0.027290]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027290339107880496 min-hit@10:0.015596663039535727 min-rhit@10:0.5214581066376496 pop-kl@10:1.4438572181070057 rhit@10:2.5097274968779018\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 56 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 57\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 164.05it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 57 training [time: 9.80s, train loss: 284.3163]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 57 evaluating [time: 81.05s, hit@10: 0.027410]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027410419802107015 min-hit@10:0.015596663039535727 min-rhit@10:0.5393035908596301 pop-kl@10:1.4361510003140125 rhit@10:2.487990809824202\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 57 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 58\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.12it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 58 training [time: 9.86s, train loss: 284.1884]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 58 evaluating [time: 81.00s, hit@10: 0.027346]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027346376765186205 min-hit@10:0.014878621769772905 min-rhit@10:0.585103415857098 pop-kl@10:1.450620991450712 rhit@10:2.5023083512120143\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 59\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.15it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 59 training [time: 9.92s, train loss: 284.0106]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 59 evaluating [time: 80.57s, hit@10: 0.027587]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027586538153639244 min-hit@10:0.016760794315904538 min-rhit@10:0.5713565469713456 pop-kl@10:1.2188402048706126 rhit@10:2.5525243363540295\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 59 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 60\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.16it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 60 training [time: 9.86s, train loss: 283.7595]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 60 evaluating [time: 80.64s, hit@10: 0.027122]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02712222613596337 min-hit@10:0.015233949945593036 min-rhit@10:0.4702575262966993 pop-kl@10:1.4466131451704678 rhit@10:2.4530338787665316\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 61\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.75it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 61 training [time: 9.88s, train loss: 283.6201]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 61 evaluating [time: 81.00s, hit@10: 0.027402]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027402414422491913 min-hit@10:0.01632208922742111 min-rhit@10:0.49392092854552055 pop-kl@10:1.4331957306712453 rhit@10:2.4748952095808385\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 62\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 161.77it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 62 training [time: 9.94s, train loss: 283.5554]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 62 evaluating [time: 81.00s, hit@10: 0.027843]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027842710301322487 min-hit@10:0.016684802321363802 min-rhit@10:0.5448059484947407 pop-kl@10:1.432776824707408 rhit@10:2.5171346344743664\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 62 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 63\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.80it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 63 training [time: 9.88s, train loss: 283.3840]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 63 evaluating [time: 80.89s, hit@10: 0.027202]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02720227993211438 min-hit@10:0.014871236851650345 min-rhit@10:0.45797606093579973 pop-kl@10:1.4158099939062003 rhit@10:2.4915050113676394\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 64\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.08it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 64 training [time: 9.86s, train loss: 283.3611]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.47it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 64 evaluating [time: 82.83s, hit@10: 0.027683]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02768260270902046 min-hit@10:0.014871236851650345 min-rhit@10:0.4762966993108452 pop-kl@10:1.4238650708291485 rhit@10:2.514312978321432\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 65\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.58it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 65 training [time: 9.83s, train loss: 283.1872]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:23<00:00,  1.46it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 65 evaluating [time: 83.32s, hit@10: 0.027611]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02761055429248455 min-hit@10:0.01644479248238058 min-rhit@10:0.49204899195654445 pop-kl@10:1.6069835299419428 rhit@10:2.504124291523904\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 66\n",
      "Train: 100%|██████████| 1608/1608 [00:10<00:00, 159.65it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 66 training [time: 10.07s, train loss: 282.9436]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:23<00:00,  1.46it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 66 evaluating [time: 83.36s, hit@10: 0.027939]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027938774856703704 min-hit@10:0.014487079091620987 min-rhit@10:0.5136796197639194 pop-kl@10:1.4332616422985895 rhit@10:2.501569454673541\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 66 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 67\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 161.97it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 67 training [time: 9.93s, train loss: 282.9354]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.50it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 67 evaluating [time: 81.48s, hit@10: 0.027779]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027778667264401678 min-hit@10:0.016942976862816542 min-rhit@10:0.5390958947038547 pop-kl@10:1.427658835636235 rhit@10:2.4844542732716386\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 68\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.63it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 68 training [time: 9.83s, train loss: 282.8506]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 68 evaluating [time: 80.47s, hit@10: 0.027843]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027842710301322487 min-hit@10:0.01632208922742111 min-rhit@10:0.5218969894813204 pop-kl@10:1.422740911591777 rhit@10:2.552092286016203\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 69\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 161.80it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 69 training [time: 9.94s, train loss: 282.7101]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 69 evaluating [time: 80.69s, hit@10: 0.027747]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02774664574594127 min-hit@10:0.016942976862816542 min-rhit@10:0.5296432675232425 pop-kl@10:1.4519127215305998 rhit@10:2.5737897467097888\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 70\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 70 training [time: 9.90s, train loss: 282.5086]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 70 evaluating [time: 80.11s, hit@10: 0.028027]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02802683403246982 min-hit@10:0.017410228509249184 min-rhit@10:0.5582999059855844 pop-kl@10:1.4301173505394287 rhit@10:2.5833614589003813\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 70 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 71\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.69it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 71 training [time: 9.89s, train loss: 282.3853]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 71 evaluating [time: 80.56s, hit@10: 0.027843]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027842710301322487 min-hit@10:0.015233949945593036 min-rhit@10:0.5010083424011608 pop-kl@10:1.4448156052790644 rhit@10:2.562051538633962\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 72\n",
      "Train: 100%|██████████| 1608/1608 [00:10<00:00, 160.68it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 72 training [time: 10.01s, train loss: 282.3134]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 72 evaluating [time: 80.59s, hit@10: 0.027891]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027890742579013098 min-hit@10:0.015596663039535727 min-rhit@10:0.5283532825535002 pop-kl@10:1.4458123197898198 rhit@10:2.559967418104966\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 73\n",
      "Train: 100%|██████████| 1608/1608 [00:10<00:00, 156.78it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 73 training [time: 10.26s, train loss: 282.3322]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.50it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 73 evaluating [time: 81.17s, hit@10: 0.027899]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.0278987479586282 min-hit@10:0.014871236851650345 min-rhit@10:0.48351468988030477 pop-kl@10:1.44080417126384 rhit@10:2.5860077171859492\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 74\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.86it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 74 training [time: 9.88s, train loss: 282.1956]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 74 evaluating [time: 81.07s, hit@10: 0.027955]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027954785615933907 min-hit@10:0.014871236851650345 min-rhit@10:0.5235364526659412 pop-kl@10:1.4468608244665995 rhit@10:2.5654258061417274\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 4 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 75\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.96it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 75 training [time: 9.87s, train loss: 282.1268]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 75 evaluating [time: 80.64s, hit@10: 0.027779]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027778667264401678 min-hit@10:0.01632208922742111 min-rhit@10:0.5326296699310845 pop-kl@10:1.4440460367265957 rhit@10:2.558681113708413\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 5 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 76\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.90it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 76 training [time: 9.87s, train loss: 282.1862]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 76 evaluating [time: 80.94s, hit@10: 0.027675]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02767459732940536 min-hit@10:0.01632208922742111 min-rhit@10:0.5450489662676823 pop-kl@10:1.4349190267448868 rhit@10:2.509368615709757\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 6 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 77\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.17it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 77 training [time: 9.92s, train loss: 281.9517]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 77 evaluating [time: 80.72s, hit@10: 0.027699]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027698613468250664 min-hit@10:0.01644479248238058 min-rhit@10:0.5409406664577456 pop-kl@10:1.4451137185249876 rhit@10:2.529613420218386\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 7 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 78\n",
      "Train: 100%|██████████| 1608/1608 [00:10<00:00, 159.79it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 78 training [time: 10.07s, train loss: 281.9082]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 78 evaluating [time: 80.80s, hit@10: 0.027915]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027914758717858403 min-hit@10:0.01605324980422866 min-rhit@10:0.5282009430540443 pop-kl@10:1.45041675688576 rhit@10:2.541296791443851\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 8 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 79\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 161.94it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 79 training [time: 9.93s, train loss: 281.7454]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 79 evaluating [time: 81.02s, hit@10: 0.028091]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02809087706939063 min-hit@10:0.018010963194988253 min-rhit@10:0.5657035412096522 pop-kl@10:1.4412986973483757 rhit@10:2.5216167664670657\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 79 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 80\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.87it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 80 training [time: 9.88s, train loss: 281.7928]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 80 evaluating [time: 80.91s, hit@10: 0.028227]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028226968522847354 min-hit@10:0.018010963194988253 min-rhit@10:0.5446411783140082 pop-kl@10:1.4318585098193302 rhit@10:2.5707144000768514\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 80 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 81\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.59it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 81 training [time: 9.89s, train loss: 281.5458]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.50it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 81 evaluating [time: 81.42s, hit@10: 0.028019]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028018828652854717 min-hit@10:0.016836335160532498 min-rhit@10:0.5115778019586508 pop-kl@10:1.425198703827928 rhit@10:2.581969483492907\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 82\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 161.90it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 82 training [time: 9.93s, train loss: 281.6072]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 82 evaluating [time: 80.93s, hit@10: 0.028067]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028066860930545327 min-hit@10:0.017047515415306493 min-rhit@10:0.5483822996010156 pop-kl@10:1.4268801373169824 rhit@10:2.5712718947132474\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 83\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.04it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 83 training [time: 9.93s, train loss: 281.3649]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 83 evaluating [time: 80.57s, hit@10: 0.028171]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028170930865541646 min-hit@10:0.017772941603191875 min-rhit@10:0.5459992745738121 pop-kl@10:1.4275164469759198 rhit@10:2.5467809568029716\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 84\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 161.20it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 84 training [time: 9.98s, train loss: 281.3379]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 84 evaluating [time: 80.62s, hit@10: 0.028155]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028154920106311442 min-hit@10:0.01644479248238058 min-rhit@10:0.5676240467982868 pop-kl@10:1.4350857240802413 rhit@10:2.5433892375676455\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 4 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 85\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 163.03it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 85 training [time: 9.87s, train loss: 281.3065]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 85 evaluating [time: 80.48s, hit@10: 0.028355]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028355054596688974 min-hit@10:0.017047515415306493 min-rhit@10:0.5267428364163946 pop-kl@10:1.4405711870901412 rhit@10:2.6138801274456442\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 85 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 86\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 161.98it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 86 training [time: 9.93s, train loss: 281.1544]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.49it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 86 evaluating [time: 81.97s, hit@10: 0.028123]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028122898587851036 min-hit@10:0.018135654697134566 min-rhit@10:0.5886388801838504 pop-kl@10:1.4428449027085852 rhit@10:2.548850587594864\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 87\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.47it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 87 training [time: 9.90s, train loss: 281.0364]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.48it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 87 evaluating [time: 82.19s, hit@10: 0.027931]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027930769477088602 min-hit@10:0.017047515415306493 min-rhit@10:0.5259630032644178 pop-kl@10:1.4221275672471254 rhit@10:2.5594790098946487\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 88\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 161.93it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 88 training [time: 9.93s, train loss: 281.0338]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:23<00:00,  1.46it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 88 evaluating [time: 83.48s, hit@10: 0.027811]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027810688782862084 min-hit@10:0.015596663039535727 min-rhit@10:0.4397896264055132 pop-kl@10:1.4126159243026581 rhit@10:2.570194130455666\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 89\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 161.01it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 89 training [time: 9.99s, train loss: 281.1170]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.48it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 89 evaluating [time: 82.51s, hit@10: 0.027939]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027938774856703704 min-hit@10:0.017047515415306493 min-rhit@10:0.5518150005223024 pop-kl@10:1.4099207551798854 rhit@10:2.5892946460021142\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 4 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 90\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.37it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 90 training [time: 9.91s, train loss: 281.0448]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 90 evaluating [time: 80.78s, hit@10: 0.027731]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02773063498671107 min-hit@10:0.014508523757707652 min-rhit@10:0.4819151251360174 pop-kl@10:1.4312999482845297 rhit@10:2.5073824009734538\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 5 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 91\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.13it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 91 training [time: 9.92s, train loss: 280.9309]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 91 evaluating [time: 80.70s, hit@10: 0.028155]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028154920106311442 min-hit@10:0.017410228509249184 min-rhit@10:0.5952047425049619 pop-kl@10:1.433111380666879 rhit@10:2.564445147138877\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 6 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 92\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.80it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 92 training [time: 9.88s, train loss: 280.8376]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 92 evaluating [time: 80.42s, hit@10: 0.028339]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028339043837458774 min-hit@10:0.01605324980422866 min-rhit@10:0.5703107698736029 pop-kl@10:1.419396196239163 rhit@10:2.5433687437958308\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 7 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 93\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 161.77it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 93 training [time: 9.94s, train loss: 280.8885]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 93 evaluating [time: 80.31s, hit@10: 0.028491]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.0284911460501457 min-hit@10:0.017619420516836334 min-rhit@10:0.602854552049329 pop-kl@10:1.43916574692065 rhit@10:2.5915429568670145\n",
      "[INFO] MF-MoRec-Pretrain: Saving best model at epoch 93 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 94\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 161.43it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 94 training [time: 9.96s, train loss: 280.6877]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.52it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 94 evaluating [time: 80.48s, hit@10: 0.028403]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028403086874379584 min-hit@10:0.01644479248238058 min-rhit@10:0.5985662801629583 pop-kl@10:1.458068042283386 rhit@10:2.566268532453809\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 1 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 95\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.02it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 95 training [time: 9.93s, train loss: 280.7380]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 95 evaluating [time: 80.68s, hit@10: 0.028107]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028106887828620832 min-hit@10:0.017047515415306493 min-rhit@10:0.5705949023294683 pop-kl@10:1.4633002967889333 rhit@10:2.5214842774344364\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 2 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 96\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 161.90it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 96 training [time: 9.93s, train loss: 280.7839]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.50it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 96 evaluating [time: 81.17s, hit@10: 0.027995]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.027994812514009416 min-hit@10:0.01644479248238058 min-rhit@10:0.5760863257163583 pop-kl@10:1.6012026071438816 rhit@10:2.5191426238432224\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 3 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 97\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.03it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 97 training [time: 9.93s, train loss: 280.4664]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 97 evaluating [time: 80.73s, hit@10: 0.028395]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028395081494764482 min-hit@10:0.01632208922742111 min-rhit@10:0.5927602466449039 pop-kl@10:1.4362958463690454 rhit@10:2.535346953152519\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 4 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 98\n",
      "Train: 100%|██████████| 1608/1608 [00:10<00:00, 160.56it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 98 training [time: 10.02s, train loss: 280.5165]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 98 evaluating [time: 80.85s, hit@10: 0.028179]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028178936245156744 min-hit@10:0.016836335160532498 min-rhit@10:0.5535763511062749 pop-kl@10:1.4321780930169892 rhit@10:2.5728247782509843\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 5 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 99\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 161.90it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 99 training [time: 9.93s, train loss: 280.5947]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 99 evaluating [time: 80.70s, hit@10: 0.028387]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02838707611514938 min-hit@10:0.017227877838684416 min-rhit@10:0.6185448657683067 pop-kl@10:1.464639527769428 rhit@10:2.5823036280380416\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 6 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 100\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.06it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 100 training [time: 9.92s, train loss: 280.5529]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 100 evaluating [time: 80.74s, hit@10: 0.028115]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028114893208235934 min-hit@10:0.016836335160532498 min-rhit@10:0.5589662676822634 pop-kl@10:1.4476192936187853 rhit@10:2.5651288065580067\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 7 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 101\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 161.67it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 101 training [time: 9.95s, train loss: 280.5553]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 101 evaluating [time: 80.71s, hit@10: 0.028115]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028114893208235934 min-hit@10:0.015661707126076743 min-rhit@10:0.5833228872871618 pop-kl@10:1.4487655968027178 rhit@10:2.5660447820935666\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 8 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 102\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.42it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 102 training [time: 9.90s, train loss: 280.4382]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.49it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 102 evaluating [time: 81.83s, hit@10: 0.028067]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.028066860930545327 min-hit@10:0.016836335160532498 min-rhit@10:0.553974720568265 pop-kl@10:1.4418389198314334 rhit@10:2.5876375324217875\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 9 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 103\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 160.98it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 103 training [time: 9.99s, train loss: 280.4165]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:20<00:00,  1.51it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 103 evaluating [time: 80.97s, hit@10: 0.028275]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02827500080053796 min-hit@10:0.017307341956640555 min-rhit@10:0.6169957171210697 pop-kl@10:1.2262874742086103 rhit@10:2.611523663902142\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 10 / 10\n",
      "[INFO] MF-MoRec-Pretrain: \n",
      ">> epoch 104\n",
      "Train: 100%|██████████| 1608/1608 [00:09<00:00, 162.75it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 104 training [time: 9.88s, train loss: 280.4082]\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:24<00:00,  1.45it/s]\n",
      "[INFO] MF-MoRec-Pretrain: epoch 104 evaluating [time: 84.12s, hit@10: 0.028379]\n",
      "[INFO] MF-MoRec-Pretrain: complete scores on valid set: \n",
      "hit@10:0.02837907073553428 min-hit@10:0.01644479248238058 min-rhit@10:0.6754909641700617 pop-kl@10:1.4384306788135994 rhit@10:2.6264990073329275\n",
      "[INFO] MF-MoRec-Pretrain: No better score in the epoch. Patience: 11 / 10\n",
      "[INFO] MF-MoRec-Pretrain: Finished training, best eval result in epoch 93\n",
      "[INFO] MF-MoRec-Pretrain: Constructing dataset of task type: test\n",
      "[DEBUG] MF-MoRec-Pretrain: loading test at 26/10/2023 20:08:10\n",
      "[DEBUG] MF-MoRec-Pretrain: Finished loading test at 26/10/2023 20:08:10\n",
      "[INFO] MF-MoRec-Pretrain: Finished initializing <class 'unirec.data.dataset.basedataset.BaseDataset'>\n",
      "[INFO] MF-MoRec-Pretrain: one_vs_all\n",
      "[INFO] MF-MoRec-Pretrain: Loading model from /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth. The best epoch was 93\n",
      "Evaluate: 100%|██████████| 1250/1250 [02:21<00:00,  8.86it/s]\n",
      "[INFO] MF-MoRec-Pretrain: best valid : {'hit@10': 0.0284911460501457, 'rhit@10': 2.5915429568670145, 'pop-kl@10': 1.43916574692065, 'min-hit@10': 0.017619420516836334, 'min-rhit@10': 0.602854552049329}\n",
      "[INFO] MF-MoRec-Pretrain: test result: {'hit@10': 0.016306958275961445, 'rhit@10': 1.4515302283134264, 'pop-kl@10': 1.4378998481908087, 'min-hit@10': 0.093349071380622063, 'min-rhit@10': 0.2596570821212799}\n",
      "[INFO] MF-MoRec-Pretrain: Saving test result to /home/v-huangxu/.unirec/output/Electronics/MF/result_MF-MoRec-Pretrain.2023-10-26_172919.100.tsv ...\n",
      "[INFO] MF-MoRec-Pretrain: Mission complete. Time elapsed: 161.27 minutes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger close successfully.\n",
      "{'hit@10': 0.016306958275961445, 'rhit@10': 1.4515302283134264, 'pop-kl@10': 1.4378998481908087, 'min-hit@10': 0.093349071380622063, 'min-rhit@10': 0.2596570821212799}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for arg in sys.argv:  # arguments conflict in notebooks, this is only required in notebooks\n",
    "    if \"-f\" in arg:\n",
    "        sys.argv.remove(arg)\n",
    "\n",
    "pretrain_config = deepcopy(GLOBAL_CONF)\n",
    "\n",
    "pretrain_config['checkpoint_dir'] = 'morec_pretrain_' + pretrain_config['checkpoint_dir']\n",
    "pretrain_config['exp_name'] = \"MoRec-Pretrain\"\n",
    "\n",
    "pretrain_result = main.run(pretrain_config)\n",
    "\n",
    "print(pretrain_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MoRec fine-tuning stage: multi-objective model tuning\n",
    "\n",
    "In this stage, the pretrained model is loaded and then trained successively toward a multi-objective model. \n",
    "\n",
    "Here we only need to set parameters for MoRec. There are several important arguments here.\n",
    "\n",
    "- enable_morec: to enable MoRec finetuning\n",
    "- model_file: the checkpoint file path of pretrained model, which is set as the output path of pretraining stage\n",
    "- morec_objectives: the objectives to be optimized in MoRec\n",
    "- morec_ngroup: group items according to weight. If -1, not use group\n",
    "- morec_alpha: the learning rate to update sampling weight with signed SGD in MoRec data sampler\n",
    "- morec_lambda: the coef $\\lambda$ used in loss synthesis\n",
    "- morec_expect_loss: expected loss for accuracy, used in PID-based objective coordinatoor\n",
    "- morec_beta_min, morec_beta_max: the range of output of PID\n",
    "- morec_K_p, morec_K_i: the coef of proportional and integral part of PID\n",
    "- morec_objective_controller: MoRec objective coordinator(controller), optional [\"Static\", \"PID\"]\n",
    "- morec_objective_weights: Weight to set objective preference. For PID controller, the length should be equal to the number of objectives except accuracy. For Static controller, the length should be the number of all objectives including accuracy and the last weight is for accuracy.\n",
    "- early_stop: early_stop epochs. In multi-objective settings, we could not set early stopping by minitoring one objective, so we set to -1 to disable early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] MF-Morec-Finetune: config={'gpu_id': 0, 'use_gpu': True, 'seed': 2022, 'state': 'INFO', 'verbose': 2, 'saved': True, 'use_tensorboard': 1, 'use_wandb': False, 'init_method': 'normal', 'init_std': 0.02, 'init_mean': 0.0, 'scheduler': None, 'scheduler_factor': 0.1, 'time_seq': 0, 'seq_last': False, 'has_user_emb': True, 'has_user_bias': 0, 'has_item_bias': 0, 'use_features': False, 'use_text_emb': False, 'use_position_emb': True, 'load_pretrained_model': False, 'embedding_size': 64, 'hidden_size': 128, 'inner_size': 128, 'dropout_prob': 0.0, 'epochs': 30, 'batch_size': 512, 'learning_rate': 0.001, 'optimizer': 'adam', 'eval_step': 1, 'early_stop': -1, 'clip_grad_norm': None, 'weight_decay': 1e-06, 'num_workers': 4, 'persistent_workers': False, 'pin_memory': False, 'shuffle_train': False, 'use_pre_item_emb': 0, 'loss_type': 'bpr', 'ccl_w': 150, 'ccl_m': 0.4, 'distance_type': 'dot', 'metrics': \"['hit@10', 'rhit@10', 'pop-kl@10', 'least-misery']\", 'key_metric': 'hit@10', 'test_protocol': 'one_vs_all', 'valid_protocol': 'one_vs_all', 'test_batch_size': 100, 'model': 'MF', 'dataloader': 'BaseDataset', 'max_seq_len': 10, 'history_mask_mode': 'autoagressive', 'tau': 1.0, 'enable_morec': 1, 'morec_objectives': ['fairness', 'alignment', 'revenue'], 'morec_objective_controller': 'PID', 'morec_ngroup': 40, 'morec_alpha': 0.1, 'morec_lambda': 0.2, 'morec_expect_loss': 0.2, 'morec_beta_min': 0.1, 'morec_beta_max': 1.5, 'morec_K_p': 0.05, 'morec_K_i': 0.001, 'morec_objective_weights': '[0.2,0.2,0.6]', 'group_size': -1, 'n_items': 44848, 'n_neg_test_from_sampling': 0, 'n_neg_train_from_sampling': 0, 'n_neg_valid_from_sampling': 0, 'n_users': 124917, 'test_file_format': 'user-item', 'train_file_format': 'user-item', 'user_history_file_format': 'user-item_seq', 'valid_file_format': 'user-item', 'config_dir': '/anaconda/envs/unirec/lib/python3.9/site-packages/unirec/config', 'exp_name': 'MF-Morec-Finetune', 'checkpoint_dir': 'morec_finetune_2023-10-26_17-29-19', 'dataset': 'Electronics', 'dataset_path': '/home/v-huangxu/.unirec/dataset/binary/Electronics', 'output_path': '/home/v-huangxu/.unirec/output/Electronics/MF', 'user_pre_item_emb': 0, 'valid_batch_size': 1024, 'n_sample_neg_train': 10, 'grad_clip_value': -1, 'user_history_filename': 'user_history', 'num_workers_test': 0, 'neg_by_pop_alpha': 1.0, 'item_meta_morec_filename': 'item_meta_morec.csv', 'align_dist_filename': None, 'model_file': '/home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth', 'cmd_args': {'config_dir': '/anaconda/envs/unirec/lib/python3.9/site-packages/unirec/config', 'exp_name': 'MF-Morec-Finetune', 'checkpoint_dir': 'morec_finetune_2023-10-26_17-29-19', 'model': 'MF', 'dataloader': 'BaseDataset', 'dataset': 'Electronics', 'dataset_path': '/home/v-huangxu/.unirec/dataset/binary/Electronics', 'output_path': '/home/v-huangxu/.unirec/output/Electronics/MF', 'learning_rate': 0.001, 'scheduler': None, 'dropout_prob': 0.0, 'embedding_size': 64, 'user_pre_item_emb': 0, 'loss_type': 'bpr', 'max_seq_len': 10, 'has_user_bias': 0, 'has_item_bias': 0, 'epochs': 30, 'early_stop': -1, 'batch_size': 512, 'valid_batch_size': 1024, 'n_sample_neg_train': 10, 'valid_protocol': 'one_vs_all', 'test_protocol': 'one_vs_all', 'grad_clip_value': -1, 'weight_decay': 1e-06, 'history_mask_mode': 'autoagressive', 'user_history_filename': 'user_history', 'metrics': \"['hit@10', 'rhit@10', 'pop-kl@10', 'least-misery']\", 'key_metric': 'hit@10', 'num_workers': 4, 'num_workers_test': 0, 'verbose': 2, 'neg_by_pop_alpha': 1.0, 'item_meta_morec_filename': 'item_meta_morec.csv', 'align_dist_filename': None, 'use_tensorboard': 1, 'enable_morec': 1, 'model_file': '/home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth', 'morec_objectives': ['fairness', 'alignment', 'revenue'], 'morec_ngroup': 40, 'morec_alpha': 0.1, 'morec_lambda': 0.2, 'morec_expect_loss': 0.2, 'morec_beta_min': 0.1, 'morec_beta_max': 1.5, 'morec_K_p': 0.05, 'morec_K_i': 0.001, 'morec_objective_controller': 'PID', 'morec_objective_weights': '[0.2,0.2,0.6]', 'logger_time_str': '2023-10-26_201035', 'logger_rand': 78}, 'device': device(type='cuda'), 'task': 'train', 'logger_time_str': '2023-10-26_201035', 'logger_rand': 78}\n",
      "[INFO] MF-Morec-Finetune: Loading user history from user_history ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load configuration files from /anaconda/envs/unirec/lib/python3.9/site-packages/unirec/config\n",
      "Writing logs to /home/v-huangxu/.unirec/output/Electronics/MF/MF-Morec-Finetune.2023-10-26_201035.78.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] MF-Morec-Finetune: Done. 124917 of users have history.\n",
      "[INFO] MF-Morec-Finetune: Loading model from checkpoint: /home/v-huangxu/.unirec/output/Electronics/MF/morec_pretrain_2023-10-26_17-29-19/MF-MoRec-Pretrain.pth ...\n",
      "[INFO] MF-Morec-Finetune: Constructing dataset of task type: train\n",
      "[DEBUG] MF-Morec-Finetune: loading train at 26/10/2023 20:10:36\n",
      "[DEBUG] MF-Morec-Finetune: Finished loading train at 26/10/2023 20:10:36\n",
      "[INFO] MF-Morec-Finetune: Finished initializing <class 'unirec.data.dataset.basedataset.BaseDataset'>\n",
      "[INFO] MF-Morec-Finetune: Constructing dataset of task type: train\n",
      "[DEBUG] MF-Morec-Finetune: loading valid at 26/10/2023 20:10:37\n",
      "[DEBUG] MF-Morec-Finetune: Finished loading valid at 26/10/2023 20:10:37\n",
      "[INFO] MF-Morec-Finetune: Finished initializing <class 'unirec.data.dataset.basedataset.BaseDataset'>\n",
      "[INFO] MF-Morec-Finetune: Constructing dataset of task type: valid\n",
      "[DEBUG] MF-Morec-Finetune: loading valid at 26/10/2023 20:10:37\n",
      "[DEBUG] MF-Morec-Finetune: Finished loading valid at 26/10/2023 20:10:37\n",
      "[INFO] MF-Morec-Finetune: Finished initializing <class 'unirec.data.dataset.basedataset.BaseDataset'>\n",
      "[INFO] MF-Morec-Finetune: MF(\n",
      "  (scorer_layers): InnerProductScorer()\n",
      "  (user_embedding): Embedding(124917, 64, padding_idx=0)\n",
      "  (item_embedding): Embedding(44848, 64, padding_idx=0)\n",
      ")\n",
      "Trainable parameter number: 10864960\n",
      "All trainable parameters:\n",
      "user_embedding.weight : torch.Size([124917, 64])\n",
      "item_embedding.weight : torch.Size([44848, 64])\n",
      "[INFO] MF-Morec-Finetune: tensorboard log file saved in /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19\n",
      "[DEBUG] MF-Morec-Finetune: >> Valid before training...\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static weight: [0.2, 0.2, 0.6].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.50it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 0 evaluating [time: 81.21s, hit@10: 0.028491]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.0284911460501457 min-hit@10:0.017619420516836334 min-rhit@10:0.602854552049329 pop-kl@10:1.43916574692065 rhit@10:2.5915429568670145\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 0 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 1\n",
      "Train: 100%|██████████| 1608/1608 [00:51<00:00, 31.52it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 1 training [time: 51.02s, train loss: 197.5243]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:23<00:00,  1.47it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 1 evaluating [time: 83.10s, hit@10: 0.025841]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.025841365397547153 min-hit@10:0.00797968806673921 min-rhit@10:0.36295973884657234 pop-kl@10:0.4099787140539063 rhit@10:3.769180809503987\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 1 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 2\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.70it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 2 training [time: 50.72s, train loss: 278.9457]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 2 evaluating [time: 81.91s, hit@10: 0.027306]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.0273063498671107 min-hit@10:0.009430540442509974 min-rhit@10:0.2519187522669568 pop-kl@10:0.24725769086213265 rhit@10:3.6045980498895256\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 2 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 3\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.99it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 3 training [time: 50.27s, train loss: 296.5319]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 3 evaluating [time: 81.78s, hit@10: 0.027899]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.0278987479586282 min-hit@10:0.01051867972433805 min-rhit@10:0.41646354733405877 pop-kl@10:0.2543180392906327 rhit@10:3.4591583143872686\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 3 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 4\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 32.10it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 4 training [time: 50.09s, train loss: 286.9845]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 4 evaluating [time: 82.02s, hit@10: 0.027875]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.027874731819782894 min-hit@10:0.011969532100108813 min-rhit@10:0.47929996372869055 pop-kl@10:0.265102547239193 rhit@10:3.303683275160908\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 4 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 5\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 32.01it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 5 training [time: 50.23s, train loss: 270.1476]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 5 evaluating [time: 81.74s, hit@10: 0.027891]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.027890742579013098 min-hit@10:0.01378309756982227 min-rhit@10:0.5638556401886108 pop-kl@10:0.3009789730932319 rhit@10:3.2691956995100706\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 5 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 6\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.58it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 6 training [time: 50.93s, train loss: 254.2980]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 6 evaluating [time: 81.74s, hit@10: 0.028123]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028122898587851036 min-hit@10:0.015596663039535727 min-rhit@10:0.6391272328423692 pop-kl@10:0.32433289172915186 rhit@10:3.294509750552371\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 6 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 7\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.93it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 7 training [time: 50.37s, train loss: 241.7643]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.50it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 7 evaluating [time: 81.53s, hit@10: 0.027963]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.02796279099554901 min-hit@10:0.014871236851650345 min-rhit@10:0.6244369581113549 pop-kl@10:0.3300656610901806 rhit@10:3.2980876749175447\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 7 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 8\n",
      "Train: 100%|██████████| 1608/1608 [00:51<00:00, 31.51it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 8 training [time: 51.04s, train loss: 232.9380]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.50it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 8 evaluating [time: 81.37s, hit@10: 0.028331]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028331038457843672 min-hit@10:0.01632208922742111 min-rhit@10:0.7424187819910164 pop-kl@10:0.35188853559496114 rhit@10:3.2943942329245246\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 8 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 9\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.77it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 9 training [time: 50.61s, train loss: 227.2934]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 9 evaluating [time: 81.81s, hit@10: 0.028467]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028467129911300394 min-hit@10:0.017410228509249184 min-rhit@10:0.7147707092865351 pop-kl@10:0.3908170222415516 rhit@10:3.3337099330750264\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 9 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 10\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.91it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 10 training [time: 50.39s, train loss: 223.9437]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.50it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 10 evaluating [time: 81.30s, hit@10: 0.028259]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.02825899004130776 min-hit@10:0.015233949945593036 min-rhit@10:0.6759013420384477 pop-kl@10:0.3824135222723405 rhit@10:3.385562698133146\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 10 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 11\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.67it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 11 training [time: 50.77s, train loss: 222.5166]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 11 evaluating [time: 82.04s, hit@10: 0.028099]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.02809888244900573 min-hit@10:0.014145810663764961 min-rhit@10:0.6783056513109788 pop-kl@10:0.3800483673681989 rhit@10:3.372918281084889\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 11 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 12\n",
      "Train: 100%|██████████| 1608/1608 [00:51<00:00, 31.41it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 12 training [time: 51.19s, train loss: 222.0706]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:24<00:00,  1.44it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 12 evaluating [time: 84.97s, hit@10: 0.028163]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028162925485926544 min-hit@10:0.01342038447587958 min-rhit@10:0.6338810301051868 pop-kl@10:0.3993847157917998 rhit@10:3.384182250472318\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 12 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 13\n",
      "Train: 100%|██████████| 1608/1608 [00:52<00:00, 30.41it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 13 training [time: 52.89s, train loss: 222.5411]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:23<00:00,  1.47it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 13 evaluating [time: 83.22s, hit@10: 0.028187]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028186941624771845 min-hit@10:0.01378309756982227 min-rhit@10:0.6160536815379035 pop-kl@10:0.3967535774242392 rhit@10:3.4336779916103612\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 13 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 14\n",
      "Train: 100%|██████████| 1608/1608 [00:51<00:00, 31.43it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 14 training [time: 51.17s, train loss: 223.0710]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.50it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 14 evaluating [time: 81.60s, hit@10: 0.028563]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.02856319446668161 min-hit@10:0.014508523757707652 min-rhit@10:0.6547261516140732 pop-kl@10:0.4075479588370355 rhit@10:3.52815267860002\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 14 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 15\n",
      "Train: 100%|██████████| 1608/1608 [00:51<00:00, 31.51it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 15 training [time: 51.03s, train loss: 223.6936]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.50it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 15 evaluating [time: 81.57s, hit@10: 0.028411]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028411092253994685 min-hit@10:0.015596663039535727 min-rhit@10:0.7054679828684842 pop-kl@10:0.39532138082514046 rhit@10:3.481170626661116\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 15 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 16\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.78it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 16 training [time: 50.61s, train loss: 224.5059]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 16 evaluating [time: 81.69s, hit@10: 0.028427]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.02842710301322489 min-hit@10:0.015233949945593036 min-rhit@10:0.655836053681538 pop-kl@10:0.4022877836218697 rhit@10:3.484266226904479\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 16 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 17\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.54it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 17 training [time: 50.99s, train loss: 224.8246]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 17 evaluating [time: 81.67s, hit@10: 0.028579]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028579205225911813 min-hit@10:0.01342038447587958 min-rhit@10:0.6674029742473704 pop-kl@10:0.40221660238178714 rhit@10:3.4834483973230017\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 17 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 18\n",
      "Train: 100%|██████████| 1608/1608 [00:51<00:00, 31.32it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 18 training [time: 51.34s, train loss: 225.1447]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 18 evaluating [time: 81.97s, hit@10: 0.028291]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028291011559768164 min-hit@10:0.01378309756982227 min-rhit@10:0.5638375045339137 pop-kl@10:0.3942318127903059 rhit@10:3.460100787729355\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 18 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 19\n",
      "Train: 100%|██████████| 1608/1608 [00:51<00:00, 31.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 19 training [time: 51.06s, train loss: 225.3449]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 19 evaluating [time: 82.14s, hit@10: 0.028411]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028411092253994685 min-hit@10:0.01378309756982227 min-rhit@10:0.4451614073268045 pop-kl@10:0.4125674000973156 rhit@10:3.4864568189823566\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 19 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 20\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.60it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 20 training [time: 50.89s, train loss: 225.2985]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.48it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 20 evaluating [time: 82.25s, hit@10: 0.028563]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.02856319446668161 min-hit@10:0.014145810663764961 min-rhit@10:0.5937178092129126 pop-kl@10:0.39330202313490764 rhit@10:3.4929426174389193\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 20 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 21\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.63it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 21 training [time: 50.83s, train loss: 225.2896]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 21 evaluating [time: 82.13s, hit@10: 0.028491]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.0284911460501457 min-hit@10:0.01378309756982227 min-rhit@10:0.48431991294885746 pop-kl@10:0.4097825929777032 rhit@10:3.447734637676519\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 21 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 22\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.81it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 22 training [time: 50.55s, train loss: 225.2620]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 22 evaluating [time: 81.77s, hit@10: 0.028131]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028130903967466137 min-hit@10:0.014508523757707652 min-rhit@10:0.48423286180631125 pop-kl@10:0.4020878739361393 rhit@10:3.392084200582792\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 22 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 23\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.74it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 23 training [time: 50.66s, train loss: 225.2188]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 23 evaluating [time: 81.95s, hit@10: 0.028483]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028483140670530597 min-hit@10:0.014871236851650345 min-rhit@10:0.4897243380486035 pop-kl@10:0.40255292755220173 rhit@10:3.4436212334688907\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 23 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 24\n",
      "Train: 100%|██████████| 1608/1608 [00:51<00:00, 31.47it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 24 training [time: 51.10s, train loss: 224.9595]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.48it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 24 evaluating [time: 82.23s, hit@10: 0.028539]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028539178327836305 min-hit@10:0.014508523757707652 min-rhit@10:0.5100652883569097 pop-kl@10:0.39831440336213697 rhit@10:3.4166854526241632\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 24 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 25\n",
      "Train: 100%|██████████| 1608/1608 [00:51<00:00, 31.27it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 25 training [time: 51.42s, train loss: 225.0422]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.50it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 25 evaluating [time: 81.52s, hit@10: 0.028835]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028835377373595057 min-hit@10:0.014145810663764961 min-rhit@10:0.5636525208560029 pop-kl@10:0.40355097582292015 rhit@10:3.451041099618944\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 25 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 26\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.66it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 26 training [time: 50.80s, train loss: 224.7432]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:21<00:00,  1.50it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 26 evaluating [time: 81.45s, hit@10: 0.028611]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028611226744372217 min-hit@10:0.014145810663764961 min-rhit@10:0.499651795429815 pop-kl@10:0.4148614563095241 rhit@10:3.4029579077139838\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 26 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 27\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.56it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 27 training [time: 50.95s, train loss: 224.6855]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:24<00:00,  1.45it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 27 evaluating [time: 84.17s, hit@10: 0.028467]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028467129911300394 min-hit@10:0.01342038447587958 min-rhit@10:0.4468298875589408 pop-kl@10:0.39998640891813225 rhit@10:3.403690079733581\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 27 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 28\n",
      "Train: 100%|██████████| 1608/1608 [00:52<00:00, 30.38it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 28 training [time: 52.93s, train loss: 224.6885]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:23<00:00,  1.46it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 28 evaluating [time: 83.84s, hit@10: 0.028307]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028307022318998367 min-hit@10:0.01595937613347842 min-rhit@10:0.5655966630395357 pop-kl@10:0.408281946371197 rhit@10:3.405583832335329\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 28 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 29\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.83it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 29 training [time: 50.52s, train loss: 224.7534]\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "Evaluate: 100%|██████████| 122/122 [01:22<00:00,  1.49it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 29 evaluating [time: 82.09s, hit@10: 0.028483]\n",
      "[INFO] MF-Morec-Finetune: complete scores on valid set: \n",
      "hit@10:0.028483140670530597 min-hit@10:0.015596663039535727 min-rhit@10:0.7188066739209286 pop-kl@10:0.4069990601887098 rhit@10:3.463679832847674\n",
      "[INFO] MF-Morec-Finetune: Saving best model at epoch 29 to /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth\n",
      "[INFO] MF-Morec-Finetune: \n",
      ">> epoch 30\n",
      "Train: 100%|██████████| 1608/1608 [00:50<00:00, 31.64it/s]\n",
      "[INFO] MF-Morec-Finetune: epoch 30 training [time: 50.82s, train loss: 224.7160]\n",
      "[INFO] MF-Morec-Finetune: Constructing dataset of task type: test\n",
      "[DEBUG] MF-Morec-Finetune: loading test at 26/10/2023 21:17:35\n",
      "[DEBUG] MF-Morec-Finetune: Finished loading test at 26/10/2023 21:17:35\n",
      "[INFO] MF-Morec-Finetune: Finished initializing <class 'unirec.data.dataset.basedataset.BaseDataset'>\n",
      "[INFO] MF-Morec-Finetune: one_vs_all\n",
      "[INFO] MF-Morec-Finetune: Loading model from /home/v-huangxu/.unirec/output/Electronics/MF/morec_finetune_2023-10-26_17-29-19/MF-Morec-Finetune.pth. The best epoch was 29\n",
      "Evaluate: 100%|██████████| 1250/1250 [02:16<00:00,  9.13it/s]\n",
      "[INFO] MF-Morec-Finetune: best valid : {'hit@10': 0.028483140670530597, 'rhit@10': 3.463679832847674, 'pop-kl@10': 0.4069990601887098, 'min-hit@10': 0.015596663039535727, 'min-rhit@10': 0.7188066739209286}\n",
      "[INFO] MF-Morec-Finetune: test result: {'hit@10': 0.017051458580165872, 'rhit@10': 2.04236959236607, 'pop-kl@10': 0.40707595507603583, 'min-hit@10': 0.010516894159767285, 'min-rhit@10': 0.38793632874237977}\n",
      "[INFO] MF-Morec-Finetune: Saving test result to /home/v-huangxu/.unirec/output/Electronics/MF/result_MF-Morec-Finetune.2023-10-26_201035.78.tsv ...\n",
      "[INFO] MF-Morec-Finetune: Mission complete. Time elapsed: 69.30 minutes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger close successfully.\n"
     ]
    }
   ],
   "source": [
    "# MoRec multi-objective post-training (fine-tuning) stage \n",
    "morec_config = deepcopy(GLOBAL_CONF)\n",
    "\n",
    "morec_config['enable_morec'] = 1\n",
    "morec_config['exp_name'] = 'Morec-Finetune'\n",
    "\n",
    "# pretrained model file is loaded by the `model_file` argument\n",
    "morec_config['model_file'] = os.path.join(pretrain_config['output_path'], pretrain_config['checkpoint_dir'], f\"{pretrain_config['model']}-{pretrain_config['exp_name']}.pth\")\n",
    "morec_config['checkpoint_dir'] = \"morec_finetune_\" + morec_config['checkpoint_dir']\n",
    "\n",
    "# MoRec parameters\n",
    "morec_config['morec_objectives']=['fairness', 'alignment', 'revenue']\n",
    "morec_config[\"morec_ngroup\"] = 40\n",
    "morec_config[\"morec_alpha\"] = 0.1\n",
    "morec_config[\"morec_lambda\"] = 0.2\n",
    "morec_config[\"morec_expect_loss\"] = 0.20\n",
    "morec_config[\"morec_beta_min\"] = 0.1\n",
    "morec_config[\"morec_beta_max\"] = 1.5\n",
    "morec_config[\"morec_K_p\"] = 0.05\n",
    "morec_config[\"morec_K_i\"] = 0.001\n",
    "morec_config[\"morec_objective_controller\"] = \"PID\"\n",
    "morec_config[\"morec_objective_weights\"] = \"[0.2,0.2,0.6]\"\n",
    "\n",
    "morec_config[\"epochs\"] = 30\n",
    "morec_config[\"early_stop\"] = -1\n",
    "\n",
    "morec_result = main.run(morec_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Comparisons\n",
    "\n",
    "The MoRec framework could improve model's performance in rhit@10, pop-kl@10, min-hit@10, which represent revenue, alignment and fairness respectively. And the improvements only sacrificy little accuracy, resulting in a 2.08% relative drop in term of hit@10. \n",
    "\n",
    "Note, the details of metrics used here are given in our [paper](https://arxiv.org/abs/2310.13260v1). The higher metrics represent the better performance, except the pop-kl.\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td>Accuracy (hit@10)</td>\n",
    "        <td>Revenue (rhit@10)</td>\n",
    "        <td>Alignment (pop-kl@10)</td>\n",
    "        <td>Fairness(min-hit@10)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Pretrain</td>\n",
    "        <td>0.01630</td>\n",
    "        <td>1.4515</td>\n",
    "        <td>1.4379</td>\n",
    "        <td>0.09335</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MoRec</td>\n",
    "        <td>0.01705</td>\n",
    "        <td>2.0424</td>\n",
    "        <td>0.4071</td>\n",
    "        <td>0.01052</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain:  {'hit@10': 0.016306958275961445, 'rhit@10': 1.4515302283134264, 'pop-kl@10': 1.4378998481908087, 'min-hit@10': 0.093349071380622063, 'min-rhit@10': 0.2596570821212799}\n",
      "Finetune:  {'hit@10': 0.017051458580165872, 'rhit@10': 2.04236959236607, 'pop-kl@10': 0.40707595507603583, 'min-hit@10': 0.010516894159767285, 'min-rhit@10': 0.38793632874237977}\n"
     ]
    }
   ],
   "source": [
    "print(\"Pretrain: \", pretrain_result)\n",
    "print(\"Finetune: \", morec_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unirec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
